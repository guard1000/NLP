{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(TPU)KoELECTRA 뉴스분류_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3ea153109c664efbafb3fd3b5bebcb40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_83f7af66e5da401192a7f19a895ae908",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9b292de75b9949c399f450e18aba1ecc",
              "IPY_MODEL_7ccc6c9297534a3cbeb025c407ac8eed"
            ]
          }
        },
        "83f7af66e5da401192a7f19a895ae908": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b292de75b9949c399f450e18aba1ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e1b3b523daff493a9ad39e7d01a8d22c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 263326,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 263326,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a5d17c679644caca89d5e8d0ab76896"
          }
        },
        "7ccc6c9297534a3cbeb025c407ac8eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2135c3891a104cccbfaf8dc2869992d7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 263k/263k [00:00&lt;00:00, 391kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9fcb07c133994d8999d72c06ede77ecf"
          }
        },
        "e1b3b523daff493a9ad39e7d01a8d22c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a5d17c679644caca89d5e8d0ab76896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2135c3891a104cccbfaf8dc2869992d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9fcb07c133994d8999d72c06ede77ecf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ef714bb2c2d4c52b417cead0db2ccff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1dacd88e669e490eb93730b224e31a93",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_09c4c25c391b40a6b058ba8950ce0250",
              "IPY_MODEL_be25ee10d00344da81498c24f40b1473"
            ]
          }
        },
        "1dacd88e669e490eb93730b224e31a93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09c4c25c391b40a6b058ba8950ce0250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7712851fef75462bb9a7a0eb9cdcd7cc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 61,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 61,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e07b18ef36a409e916b137c85dbce34"
          }
        },
        "be25ee10d00344da81498c24f40b1473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e1bbe4fb0c56492f9ce118910244a762",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 61.0/61.0 [00:00&lt;00:00, 415B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af3d16ddc84a48c2b5b68129c9612006"
          }
        },
        "7712851fef75462bb9a7a0eb9cdcd7cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e07b18ef36a409e916b137c85dbce34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1bbe4fb0c56492f9ce118910244a762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af3d16ddc84a48c2b5b68129c9612006": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "afe5fa905dda4dd88f00f63adf50411f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e6e65f7ac40b44dbae1d9c54d57af9ca",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9888cb4cef214552bbc140cf53dfb259",
              "IPY_MODEL_8ed3cb3e6624459b965d3bf143be2151"
            ]
          }
        },
        "e6e65f7ac40b44dbae1d9c54d57af9ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9888cb4cef214552bbc140cf53dfb259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f65a3c732c204e4889ea6315c300322c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 467,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 467,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c7d8bd04608406f9fc02618c8bf788c"
          }
        },
        "8ed3cb3e6624459b965d3bf143be2151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_47ec55a3959c40868c08a702e0a317b6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 467/467 [00:00&lt;00:00, 3.61kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e494a95d55d74605b48f35cfcf4657db"
          }
        },
        "f65a3c732c204e4889ea6315c300322c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c7d8bd04608406f9fc02618c8bf788c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47ec55a3959c40868c08a702e0a317b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e494a95d55d74605b48f35cfcf4657db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c506e30139f4d9586bc305d0ae07fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb6bebbf95f84acfb2c2f46ee3b3462b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_74bef3aabf02410f82a89a653f879809",
              "IPY_MODEL_5bc9c89216fc40359d2bbce244e3ab6f"
            ]
          }
        },
        "fb6bebbf95f84acfb2c2f46ee3b3462b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74bef3aabf02410f82a89a653f879809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3aa6bb73e0fb466fa5ea0bc71bbebf70",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 451776329,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 451776329,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a929ccfd4a4b442c9fe23f125269f02b"
          }
        },
        "5bc9c89216fc40359d2bbce244e3ab6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a24b40f2c5a748f986a95b8e931f6770",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 452M/452M [00:07&lt;00:00, 64.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6a7ac81ed024431bd8dee026bef9648"
          }
        },
        "3aa6bb73e0fb466fa5ea0bc71bbebf70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a929ccfd4a4b442c9fe23f125269f02b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a24b40f2c5a748f986a95b8e931f6770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6a7ac81ed024431bd8dee026bef9648": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guard1000/NLP/blob/master/(TPU)KoELECTRA_%EB%89%B4%EC%8A%A4%EB%B6%84%EB%A5%98_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY0oR4s7scKf"
      },
      "source": [
        "#목차\n",
        "이번 실습은 <b>1) 뉴스 데이터 불러오기 및 전처리 2) KoELECTRA 인풋 만들기 3) KoELECTRA를 활용한 유형분류 모델 만들기 4) 훈련 및 성능 검증 5) 실제 데이터로 실습하기</b>로 구성되어 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcxkFoFEulHa"
      },
      "source": [
        "#KoELECTRA를 활용하여 네이버 뉴스 유형분류기 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_X3MbBns6fL"
      },
      "source": [
        "## 네이버 뉴스 데이터 불러오기 및 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO3MDrbfpfxV"
      },
      "source": [
        "huggingface 패키지를 Colab에 설치합니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AB7YtQ3rZzF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00a22978-77dd-4eb3-9ea5-18e249fd81ae"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 7.0MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 47.2MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 28.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=3413087aed59870060d05151e0b0bebf8829b5198fdda0cbd7188515a14dee60\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdvo-EpaqFev"
      },
      "source": [
        "텐서플로우 2와 필요한 모듈들을 임포트합니다.  \n",
        "최근에 텐서플로우 기본 버전은 2로 바뀌었습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRXvtgWrrdk5"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import *\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgUYFux4rPVC"
      },
      "source": [
        "이번 예제에서 사용할 네이버 뉴스 데이터를 로드 합니다.\r\n",
        "\r\n",
        "(예전에 학습용으로 크롤링 및 전처리 해둠)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL5IbOJ5_FE_",
        "outputId": "58054af3-d117-4e80-d456-67c641010d72"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ5lIpQLrOa3"
      },
      "source": [
        "dummy = pd.read_csv(\"/content/drive/My Drive/data/Article_shuffled.csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YXI6Q-hsQpn"
      },
      "source": [
        "dummy.rename(columns={'이해찬 민주당 단배식서 내년 총선 압승해 민주주의 정착 새해 첫날인 1일 여권은 집권 3년 차를 맞은 문재인 정부의 성공을 기원하며 내부 결속 의지를 다졌다. 특히 여당인 더불어민주당은 2020년 총선 압승 을 발판으로 2022년 정권 재창출 을 이뤄내겠다고 다짐했다. 문희상 국회의장은 이날 서울 한남동 의장 공관에서 신년 기자간담회를 열고 집권 3년 차는 아주 중요한 전기 라고 했다. 그러면서 올해를 황금돼지해라고 부르는데 저는 검은 돼지든 흰 돼지든 무게만 나가면 된다고 생각한다 며 흑돈백돈 黑豚白豚 론 을 펼쳤다. 중국 덩샤오핑의 흑묘백묘론 검은 고양이든 흰 고양이든 쥐만 잘 잡으면 된다 을 차용해 올해 경제 발전이 가장 중요한 과제라는 점을 강조한 것으로 해석됐다. 문 의장은 황금으로 누런 돼지라고 하면 이건 정말 대박 이라며 번영의 돼지해에 문재인 정부도 성공하고 우리도 성공하는 한 해가 되길 바란다 고 했다. 민주당은 이날 여의도 당사에서 신년인사회를 겸한 단배식을 열었다. 이해찬 대표는 재작년에는 정권 교체를 이뤘고 작년에는 지방선거에서 민주당이 압도적 승리를 거뒀다 며 이것을 기반으로 내년 총선에서 아주 크게 압승하는 정치적 성과를 올려야 한다 고 했다. 이 대표는 총선에서 크게 이기는 게 이 나라 민주주의를 정착시키는 데 아주 중요한 과업 이라며 그래야 2022년 대선에서 정권을 재창출해 민주당이 평화와 민주주의를 지키는 마지막 보루가 될 수 있다 고 했다. 이 대표는 남북 관계와 관련해 지난해 70년 분단 체제에서 평화 체제로 전환되는 역사적 한 획을 그었다 며 아마 남북 정상회담이 올해 일찍 열릴 가능성이 크다 고 했다. 경제 문제에 대해선 어렵다곤 하지만 조금씩은 나아지고 있다 고 했다. 그러자 홍영표 원내대표는 맞바람을 향해 돛을 펼친다 는 역풍장범 逆風張帆 이라는 말이 있다 며 앞으로도 많은 시련과 도전이 기다리고 있다. 이 대표를 중심으로 더욱 단결하는 한 해가 되도록 하자 고 했다. 민주당 지도부는 이날 오전 서울 국립현충원에서 김영삼·김대중 전 대통령 묘역을 참배했다. 이어 이승만·박정희 전 대통령 묘역도 찾았으나 일부 시민이 어떻게 박 전 대통령 묘역에 인사할 수 있나. 부끄럽지도 않으냐 고 항의해 분위기가 일순간 얼어붙기도 했다. 오후에는 경남 김해 봉하마을을 방문해 노무현 전 대통령 묘역을 참배했다.' : 'document', '정치': 'label'}, inplace=True)\r\n",
        "\r\n",
        "dic_category = {'경제': 0, '생활문화': 1, 'IT과학': 2, '정치': 3, '사회': 4, '오피니언': 5, '세계':6}\r\n",
        "for i in range(11000):\r\n",
        "  dummy.iloc[i].label = dic_category[dummy.iloc[i].label]\r\n",
        "\r\n",
        "train = dummy[:10000]\r\n",
        "test = dummy[10000:11000]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JFTyGGxwIwI"
      },
      "source": [
        "딥러닝 훈련에 사용 할 train 데이터와 test 데이터를 pandas dataframe 형식으로 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "JyloWrfv_bW6",
        "outputId": "66c34c09-2920-4a82-dcda-029a62d0c8ff"
      },
      "source": [
        "train[50:70]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>2019년 기해년 己亥年 첫날인 1일 오전 부산 해운대해수욕장을 찾은 시민과 관광객...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>정의당 이정미 대표가 문재인 대통령의 신년사에 대해 방향에는 전적으로 동의하지만 그...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>노조 알박기·노조원 감시 혐의 삼성이 에버랜드 현 삼성물산 리조트 부문 에 어용노조...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>문재인 대통령이 그제 고농도 미세먼지와 관련해 “재난에 준하는 상황으로 인식하고 대...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>서울 연합뉴스 인천국제공항 화물터미널에서 아시아나항공 보잉747 화물기에 화물이 탑...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>마이크 폼페이오 미국 국무장관. © AFP 뉴스1 서울 뉴스1 김정한 기자 미국이 ...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>앵커 새해 벽두부터 산불이 나 축구장의 30배 가까운 크기의 산림이 잿더미로 변했습...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>제주 뉴시스 우장호 기자 2일 오전 제주시 라마다프라자제주호텔 대연회장에서 제주상공...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>글자는 읽을 수 있지만 책을 읽지 않는 사람을 의사 문맹 책과 담 쌓은 사람·ali...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>취임사 하는 채광철 목포해경서장 목포해경 목포 연합뉴스 조근영 기자 목포해양경찰서는...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>기아자동차가 10년이 넘은 노후경유차 보유고객 대상으로 차량 교체 지원에 나선다. ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>남산 팔각정서 해맞이 후 떡국… 일출 보러온 사람들 마음 다들 간절 오후엔 사회 각...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>최근 국민연금이 조양호 대한항공 회장의 이사 재선임을 반대하기로 공식적으로 선언함으...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>성주 뉴스1 정우용 기자 1일 경북 성주군 가야산국립공원 역사신화공원 상아덤 마당에...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>AI가 지배하는 라스베이거스 인간 초기수준 으로 올라선 AI 모빌리티·헬스케어 기술...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>서울 뉴시스 최동준 기자 2일 서울 종로구 정부서울청사 별관에서 열린 2019년 정...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>청와대 과학기술보좌관 자리가 빈 지 2월 1일로 50일째를 맞았다. 전임 문미옥 보...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>체온의 열로 전력을 생산하는 패치형 열전소자를 이용해 소형 전광판을 작동한 모습. ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>국회의사당 전경 뉴스1 처음엔 관람객을 안내하는 국회 직원인 줄 알았다. 정장을 차...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>병원에서 일하던 간호조무사 실습생이 동료들 괴롭힘에 힘들다는 내용의 유서를 남기고 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             document label\n",
              "50  2019년 기해년 己亥年 첫날인 1일 오전 부산 해운대해수욕장을 찾은 시민과 관광객...     4\n",
              "51  정의당 이정미 대표가 문재인 대통령의 신년사에 대해 방향에는 전적으로 동의하지만 그...     3\n",
              "52  노조 알박기·노조원 감시 혐의 삼성이 에버랜드 현 삼성물산 리조트 부문 에 어용노조...     4\n",
              "53  문재인 대통령이 그제 고농도 미세먼지와 관련해 “재난에 준하는 상황으로 인식하고 대...     5\n",
              "54  서울 연합뉴스 인천국제공항 화물터미널에서 아시아나항공 보잉747 화물기에 화물이 탑...     0\n",
              "55  마이크 폼페이오 미국 국무장관. © AFP 뉴스1 서울 뉴스1 김정한 기자 미국이 ...     6\n",
              "56  앵커 새해 벽두부터 산불이 나 축구장의 30배 가까운 크기의 산림이 잿더미로 변했습...     4\n",
              "57  제주 뉴시스 우장호 기자 2일 오전 제주시 라마다프라자제주호텔 대연회장에서 제주상공...     3\n",
              "58  글자는 읽을 수 있지만 책을 읽지 않는 사람을 의사 문맹 책과 담 쌓은 사람·ali...     5\n",
              "59  취임사 하는 채광철 목포해경서장 목포해경 목포 연합뉴스 조근영 기자 목포해양경찰서는...     1\n",
              "60  기아자동차가 10년이 넘은 노후경유차 보유고객 대상으로 차량 교체 지원에 나선다. ...     1\n",
              "61  남산 팔각정서 해맞이 후 떡국… 일출 보러온 사람들 마음 다들 간절 오후엔 사회 각...     3\n",
              "62  최근 국민연금이 조양호 대한항공 회장의 이사 재선임을 반대하기로 공식적으로 선언함으...     5\n",
              "63  성주 뉴스1 정우용 기자 1일 경북 성주군 가야산국립공원 역사신화공원 상아덤 마당에...     4\n",
              "64  AI가 지배하는 라스베이거스 인간 초기수준 으로 올라선 AI 모빌리티·헬스케어 기술...     0\n",
              "65  서울 뉴시스 최동준 기자 2일 서울 종로구 정부서울청사 별관에서 열린 2019년 정...     3\n",
              "66  청와대 과학기술보좌관 자리가 빈 지 2월 1일로 50일째를 맞았다. 전임 문미옥 보...     5\n",
              "67  체온의 열로 전력을 생산하는 패치형 열전소자를 이용해 소형 전광판을 작동한 모습. ...     2\n",
              "68  국회의사당 전경 뉴스1 처음엔 관람객을 안내하는 국회 직원인 줄 알았다. 정장을 차...     5\n",
              "69  병원에서 일하던 간호조무사 실습생이 동료들 괴롭힘에 힘들다는 내용의 유서를 남기고 ...     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "OyFxMOw9_kry",
        "outputId": "ae724cdb-7b6e-4f0e-de5c-26117538894e"
      },
      "source": [
        "# 전체 데이터 중 가장 긴 뉴스, 뉴스들 평균  길이로 어느정도 길이로 잘라낼지 확인\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "print('뉴스 기사 최대 길이 :',max(len(l) for l in train.document))\r\n",
        "print('뉴스 기사 평균 길이 :',sum(map(len, train.document))/len(train.document))\r\n",
        "plt.hist([len(s) for s in train.document], bins=50)\r\n",
        "plt.xlabel('length of news')\r\n",
        "plt.ylabel('number of news')\r\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "뉴스 기사 최대 길이 : 16334\n",
            "뉴스 기사 평균 길이 : 930.4483\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckunJDwx_k1H",
        "outputId": "1111c6a1-91b6-423a-8174-8baae8c85779"
      },
      "source": [
        "#전체 데이터 중 특정 length 이하인 비율을 알려주는 함수\r\n",
        "def below_threshold_len(max_len, nested_list):\r\n",
        "  cnt = 0\r\n",
        "  for s in nested_list:\r\n",
        "    if(len(s) <= max_len):\r\n",
        "        cnt = cnt + 1\r\n",
        "  print('전체 데이터 중 길이가 %s 이하인 데이터의 비율: %s'%(max_len, (cnt / len(nested_list))*100))\r\n",
        "\r\n",
        "max_len = 128  # 위 그래프 보면서 임의로 값 넣어보면서 비율 확인 - 성능 별로면 이거 올려\r\n",
        "below_threshold_len(max_len, train.document)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 데이터 중 길이가 128 이하인 데이터의 비율: 17.169999999999998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRluqfcjgavO"
      },
      "source": [
        "train 데이터와 test 데이터를 전처리하도록 하겠습니다.\r\n",
        "\r\n",
        "특수 문자들을 제거하고, 띄어쓰기가 많은 부분만 간단히 전처리 해주도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFsbjiwigYgh",
        "outputId": "124e5156-2629-4198-efe1-5778a73626ac"
      },
      "source": [
        "train['document'] = train['document'].str.replace(r'[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》\\\\n\\t]+', \" \", regex=True)\r\n",
        "test['document'] = test['document'].str.replace(r'[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', \" \", regex=True)\r\n",
        "train['document'] = train['document'].str.replace(r'\\t+', \" \", regex=True)\r\n",
        "test['document'] = test['document'].str.replace(r'\\t+', \" \", regex=True)\r\n",
        "train['document'] = train['document'].str.replace(r'[\\\\n]+',\" \", regex=True)\r\n",
        "test['document'] = test['document'].str.replace(r'[\\\\n]+',\" \", regex=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp1h3X_7tHpy"
      },
      "source": [
        "## KoELECTRA 인풋 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4JGys9DrU4_"
      },
      "source": [
        "한글 데이터를 분석에 KoELECTRA를 사용해 봅시다.  \n",
        "monologg님의 KoELECTRA-base-v3 모델을 사용하도록 하겠습니다.  \n",
        "모델을 로드하기에 앞서, 토크나이저를 불러오도록 하겠습니다.  \n",
        "huggingface에서는 아주 쉽게 토크나이저를 불러올 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4Xgl9RtsGul",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "3ea153109c664efbafb3fd3b5bebcb40",
            "83f7af66e5da401192a7f19a895ae908",
            "9b292de75b9949c399f450e18aba1ecc",
            "7ccc6c9297534a3cbeb025c407ac8eed",
            "e1b3b523daff493a9ad39e7d01a8d22c",
            "0a5d17c679644caca89d5e8d0ab76896",
            "2135c3891a104cccbfaf8dc2869992d7",
            "9fcb07c133994d8999d72c06ede77ecf",
            "7ef714bb2c2d4c52b417cead0db2ccff",
            "1dacd88e669e490eb93730b224e31a93",
            "09c4c25c391b40a6b058ba8950ce0250",
            "be25ee10d00344da81498c24f40b1473",
            "7712851fef75462bb9a7a0eb9cdcd7cc",
            "4e07b18ef36a409e916b137c85dbce34",
            "e1bbe4fb0c56492f9ce118910244a762",
            "af3d16ddc84a48c2b5b68129c9612006"
          ]
        },
        "outputId": "62f58ed1-649b-40c2-a597-516a850e8b18"
      },
      "source": [
        "from transformers import ElectraTokenizer\r\n",
        "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ea153109c664efbafb3fd3b5bebcb40",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=263326.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ef714bb2c2d4c52b417cead0db2ccff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=61.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii2W5UbyuN2b"
      },
      "source": [
        "KoELECTRA를 사용하기에 앞서 가장 기초에 속하는 tokenizer 사용 방법에 대해서 잠시 배워보도록 하겠습니다.  \n",
        "tokenizer.encode => 문장을 KoELECTRA 모델의 인풋 토큰값으로 바꿔줌  \n",
        "tokenizer.tokenize => 문장을 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eybf2-OluWro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49e3b53f-1148-4d3e-ea44-eefb4f47b922"
      },
      "source": [
        "print(tokenizer.encode(\"글자는 읽을 수 있지만 책을 읽지 않는 사람을 의사 문맹 책과 담 쌓은 사람\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 11024, 4034, 3244, 4292, 2967, 3249, 17164, 3432, 4292, 3244, 4200, 3083, 4034, 6226, 4292, 6804, 2693, 5141, 3432, 4047, 2357, 3027, 4112, 6226, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CshMEDzEcvdw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6af691e-cb4a-47a9-bbf1-99cd9492fbac"
      },
      "source": [
        "print(tokenizer.tokenize(\"글자는 읽을 수 있지만 책을 읽지 않는 사람을 의사 문맹 책과 담 쌓은 사람\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['글자', '##는', '읽', '##을', '수', '있', '##지만', '책', '##을', '읽', '##지', '않', '##는', '사람', '##을', '의사', '문', '##맹', '책', '##과', '담', '쌓', '##은', '사람']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORJ-Eq61u2V1"
      },
      "source": [
        "우리가 네이버 뉴스분류를 위해, train 1만개의 데이터를 KoELECTRA의 인풋 값으로 바꿔주겠습니다.  \n",
        "KoELECTRA의 인풋은 토큰, 세그멘트, 마스크로 나눠집니다.  \n",
        "이 세 값이 KoELECTRA 모형에 들어가서, KoELECTRA 모형에 맞게 고차원으로 임베딩이 되게 되는 원리입니다. (BERT 설명 동) \n",
        "\n",
        "토큰은 말 그대로 단어를 단어사전의 위치값으로 표현해주는 것이며, \n",
        "세그멘트는 KoELECTRA 모형에서 문장이 앞 문장인지, 뒷 문장인지 표현해주는 것입니다.(본 예제는 인풋으로 문장이 하나만 들어가므로 0으로 통일)  \n",
        "마스크는 문장이 유효한 값인지, 아니면 유효하지 않은 값이라 패딩 값으로 채운 것인지를 나타냅니다.  \n",
        "문장이 유효한 값이면 1로 채우고, 유효하지 않은 값이면 0으로 채우게 됩니다.  \n",
        "문장마다 문장 길이는 다르지만, KoELECTRA의 인풋 길이는 일정해야 하므로, KoELECTRA에서 지정한 문장 길이를 초과하면 패딩값인 0을 채우게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM-XXAuCxIf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e48eeae-0c72-4b62-c5fa-20c9fb8fc240"
      },
      "source": [
        "print(tokenizer.tokenize(\"체온의 열로 전력을 생산하는 패치형 열전소자를 이용해 소형 전광판을 작동한 모습\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['체온', '##의', '열', '##로', '전력', '##을', '생산', '##하', '##는', '패치', '##형', '열전', '##소', '##자', '##를', '이용해', '소형', '전광판', '##을', '작동', '##한', '모습']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyhSwEAUxgL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a87112-7746-4625-dd62-8a47400e957d"
      },
      "source": [
        "print(tokenizer.encode(\"체온의 열로 전력을 생산하는 패치형 열전소자를 이용해 소형 전광판을 작동한 모습\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 17356, 4234, 3142, 4239, 7683, 4292, 6552, 4279, 4034, 12001, 4303, 23549, 4104, 4195, 4110, 8164, 9686, 26052, 4292, 9670, 4283, 6373, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS9ZeYY1yC3J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa91d013-7808-446d-f421-264b22524ee8"
      },
      "source": [
        "print(tokenizer.encode(\"체온의 열로 전력을 생산하는 패치형 열전소자를 이용해 소형 전광판을 작동한 모습\", max_length=128, pad_to_max_length=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2, 17356, 4234, 3142, 4239, 7683, 4292, 6552, 4279, 4034, 12001, 4303, 23549, 4104, 4195, 4110, 8164, 9686, 26052, 4292, 9670, 4283, 6373, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr-l7XNcwtQB"
      },
      "source": [
        "토큰 인풋의 예를 들면 다음과 같습니다.  \n",
        "문장을 토크나이징 하면 \"전율을 일으키는 영화. 다시 보고싶은 영화\"가  \n",
        "\"'전', '##율', '##을', '일', '##으', '##키는', '영화', '.', '다시', '보고', '##싶', '##은', '영화'\" 로 토크나이징이 됩니다.  \n",
        "이거를 KoELECTRA 인풋에 들어갈 숫자로 바꿔주면,  \n",
        "[\"101, 9665, 119183, 10622, 9641, 119185, 66815, 42428, 119, 25805, 98199, 119088, 10892, 42428, 102\"]  \n",
        "로 바뀌게 됩니다. 여기 나오는 숫자들이 KoELECTRA 인풋에 들어가는 토큰 인풋입니다.  \n",
        "KoELECTRA 모형에 들어가는 인풋은 사실 일정한 길이를 가져야 합니다.(본 예제에서는 128)  \n",
        "따라서 남는 부분은 0으로 채워지게 됩니다(패딩)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBa3KLTxyV0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c6e2cca-b73b-40d0-f010-baccce48cb48"
      },
      "source": [
        "# 세그멘트 인풋\n",
        "print([0]*128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQxClepBx5aB"
      },
      "source": [
        "세그멘트 인풋은 문장이 앞문장인지 뒷문장인지 구분해주는 역할을 하는데요  \n",
        "본 문장에서는 문장 하나만 인풋으로 들어가기 때문에 0만 들어가게 되고, 문장 길이만큼의 0이 인풋으로 들어가게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_sprXQ2yczY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf7da161-7360-414c-8108-96bbc729cdef"
      },
      "source": [
        "# 마스크 인풋\n",
        "valid_num = len(tokenizer.encode(\"체온의 열로 전력을 생산하는 패치형 열전소자를 이용해 소형 전광판을 작동한 모습\"))\n",
        "print(valid_num * [1] + (128 - valid_num) * [0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iykc56uIzH1R"
      },
      "source": [
        "마스크 인풋은 토큰 인풋에서 패딩이 아닌 부분은 1, 패딩인 부분은 0으로 두게 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wEKq5qfxH9t"
      },
      "source": [
        "종합하면,  \n",
        "KoELECTRA의 인풋은 토큰, 세그먼트, 마스크로 이루어져 있습니다.  \n",
        "\"전율을 일으키는 영화. 다시 보고싶은 영화\" 라는 문장을 가지고 예를 들면,\n",
        "\n",
        "토큰 인풋 : [101, 9665, 119183, 10622, 9641, 119185, 66815, 42428, 119, 25805, 98199, 119088, 10892, 42428, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "세그먼트 인풋 : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "마스크 인풋 : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LYpgPArzjiI"
      },
      "source": [
        "네이버 뉴스 문장들을 KoELECTRA 인풋으로 바꿔보도록 하겠습니다.  \n",
        "문장이 토큰 인풋, 세그먼트 인풋, 마스크 인풋으로 변환 됩니다.  \n",
        "huggingface에서는 순서가 [토큰 인풋, 마스크 인풋, 세그먼트 인풋] 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFFokLO0sj_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66042a88-b6a5-462d-a2c7-a12feb9e965a"
      },
      "source": [
        "def convert_data(data_df):\n",
        "    global tokenizer\n",
        "    \n",
        "    SEQ_LEN = 128 #SEQ_LEN : KoELECTRA에 들어갈 인풋의 길이\n",
        "    \n",
        "    tokens, masks, segments, targets = [], [], [], []\n",
        "    \n",
        "    for i in tqdm(range(len(data_df))):\n",
        "        # token : 문장을 토큰화함\n",
        "        token = tokenizer.encode(data_df[DATA_COLUMN][i], max_length=SEQ_LEN, truncation=True, padding='max_length')\n",
        "       \n",
        "        # 마스크는 토큰화한 문장에서 패딩이 아닌 부분은 1, 패딩인 부분은 0으로 통일\n",
        "        num_zeros = token.count(0)\n",
        "        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\n",
        "        \n",
        "        # 문장의 전후관계를 구분해주는 세그먼트는 문장이 1개밖에 없으므로 모두 0\n",
        "        segment = [0]*SEQ_LEN\n",
        "\n",
        "        # KoELECTRA 인풋으로 들어가는 token, mask, segment를 tokens, segments에 각각 저장\n",
        "        tokens.append(token)\n",
        "        masks.append(mask)\n",
        "        segments.append(segment)\n",
        "        \n",
        "        # 정답을 targets 변수에 저장해 줌\n",
        "        targets.append([data_df[LABEL_COLUMN][i] for j in range(SEQ_LEN)])\n",
        "\n",
        "    # tokens, masks, segments, 정답 변수 targets를 numpy array로 지정    \n",
        "    tokens = np.array(tokens)\n",
        "    masks = np.array(masks)\n",
        "    segments = np.array(segments)\n",
        "    targets = np.array(targets)\n",
        "\n",
        "    return [tokens, masks, segments], targets\n",
        "\n",
        "# 위에 정의한 convert_data 함수를 불러오는 함수를 정의\n",
        "def load_data(pandas_dataframe):\n",
        "    data_df = pandas_dataframe\n",
        "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
        "    data_df[LABEL_COLUMN] = data_df[LABEL_COLUMN].astype(int)\n",
        "    data_x, data_y = convert_data(data_df)\n",
        "    return data_x, data_y\n",
        "\n",
        "SEQ_LEN = 128\n",
        "BATCH_SIZE = 20\n",
        "# 뉴스 내용을 포함하고 있는 칼럼\n",
        "DATA_COLUMN = \"document\"\n",
        "# 유형을 포함하고 있는 칼럼\n",
        "LABEL_COLUMN = \"label\"\n",
        "\n",
        "# train 데이터를 KoELECTRA 인풋에 맞게 변환\n",
        "train_x, train_y = load_data(train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "100%|██████████| 10000/10000 [00:49<00:00, 203.02it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ocb17LekZVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65cae4ec-62c9-48f8-803f-4de5db9e5498"
      },
      "source": [
        "# 훈련 성능을 검증한 test 데이터를 KoELECTRA 인풋에 맞게 변환\n",
        "test.index = np.arange(0, len(test)) # test index 0부터 시작하게 변환\n",
        "test_x, test_y = load_data(test)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "100%|██████████| 1000/1000 [00:05<00:00, 187.00it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEQmCZlstYwA"
      },
      "source": [
        "## KoELECTRA 활용한 뉴스 유형분류 모델 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQXkHsfS1L7y"
      },
      "source": [
        "KoELECTRA 훈련을 빠르게 하기 위해, TPU를 사용하도록 하겠습니다.  \n",
        "TPU를 사용하시고 싶지 않으신 분은 그냥 TPU 관련 부분을 실행하지 않으면 되겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h10mLq5DhvWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "403cd567-e287-4fae-ee0e-e8c65f6c3f8c"
      },
      "source": [
        "# TPU 객체 지정\r\n",
        "TPU = True\r\n",
        "if TPU:\r\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\r\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\r\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\r\n",
        "else:\r\n",
        "  pass"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.59.105.218:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.59.105.218:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W85BlYfo2Wge",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634,
          "referenced_widgets": [
            "afe5fa905dda4dd88f00f63adf50411f",
            "e6e65f7ac40b44dbae1d9c54d57af9ca",
            "9888cb4cef214552bbc140cf53dfb259",
            "8ed3cb3e6624459b965d3bf143be2151",
            "f65a3c732c204e4889ea6315c300322c",
            "2c7d8bd04608406f9fc02618c8bf788c",
            "47ec55a3959c40868c08a702e0a317b6",
            "e494a95d55d74605b48f35cfcf4657db",
            "1c506e30139f4d9586bc305d0ae07fc4",
            "fb6bebbf95f84acfb2c2f46ee3b3462b",
            "74bef3aabf02410f82a89a653f879809",
            "5bc9c89216fc40359d2bbce244e3ab6f",
            "3aa6bb73e0fb466fa5ea0bc71bbebf70",
            "a929ccfd4a4b442c9fe23f125269f02b",
            "a24b40f2c5a748f986a95b8e931f6770",
            "d6a7ac81ed024431bd8dee026bef9648"
          ]
        },
        "outputId": "e8df2fd8-7686-4636-e6dd-4df468a442ef"
      },
      "source": [
        "from transformers import TFElectraModel\n",
        "model = TFElectraModel.from_pretrained(\"monologg/koelectra-base-v3-discriminator\", from_pt=True)\n",
        "\n",
        "# 토큰 인풋, 마스크 인풋, 세그먼트 인풋 정의\n",
        "token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\n",
        "mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\n",
        "segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\n",
        "# 인풋이 [토큰, 마스크, 세그먼트]인 모델 정의\n",
        "koelectra_outputs = model([token_inputs, mask_inputs, segment_inputs])\n",
        "# KoELECTRA 아웃풋의 텐서의 shape은 [batch_size, 문장의 길이, 768]임"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afe5fa905dda4dd88f00f63adf50411f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c506e30139f4d9586bc305d0ae07fc4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=451776329.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'electra.embeddings.position_ids', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']\n",
            "- This IS expected if you are initializing TFElectraModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFElectraModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFElectraModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fb507dd3660>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7fb519f1ce58> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fb507dd3660>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7fb519f1ce58> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fb507dd3660>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7fb519f1ce58> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fb5178ad8c8> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fb5178ad8c8> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function wrap at 0x7fb5178ad8c8> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXKy-Jsg3eKA"
      },
      "source": [
        "koelectra_outputs = koelectra_outputs[0] # 1-> 0\n",
        "classify_first = tf.keras.layers.Dense(7, activation='softmax', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(koelectra_outputs)\n",
        "\n",
        "classify_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], classify_first)\n",
        "classify_model.compile(optimizer=tf.keras.optimizers.Adam(lr=1.0e-5), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics = ['sparse_categorical_accuracy'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4Si9oO33i70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b15197ad-a17e-4779-d839-a4b19566caef"
      },
      "source": [
        "classify_model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_segment (InputLayer)      [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_electra_model (TFElectraMode TFBaseModelOutput(la 112330752   input_word_ids[0][0]             \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 input_segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128, 7)       5383        tf_electra_model[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 112,336,135\n",
            "Trainable params: 112,336,135\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUKSC6cC1T5c"
      },
      "source": [
        "유형분류에 맞는 KoELECTRA 모형을 리턴하는 함수를 정의하도록 하겠습니다.  \n",
        "TPU를 활용하려면 함수로 묶어야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90uerGX4Rl2d"
      },
      "source": [
        "def create_classify_koelectra():\n",
        "  # KoELECTRA pretrained 모델 로드\n",
        "  model = TFElectraModel.from_pretrained(\"monologg/koelectra-base-v3-discriminator\", from_pt=True)\n",
        "  # 토큰 인풋, 마스크 인풋, 세그먼트 인풋 정의\n",
        "  token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\n",
        "  mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\n",
        "  segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\n",
        "  # 인풋이 [토큰, 마스크, 세그먼트]인 모델 정의\n",
        "  koelectra_outputs = model([token_inputs, mask_inputs, segment_inputs])\n",
        "\n",
        "  koelectra_outputs = koelectra_outputs[0]\n",
        "  classify_first = tf.keras.layers.Dense(7, activation='softmax', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(koelectra_outputs)\n",
        "\n",
        "  classifiy_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], classify_first)\n",
        "  classifiy_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.00002), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics = ['sparse_categorical_accuracy'])\n",
        "  return classifiy_model"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "01CpbBDdFCc9",
        "outputId": "c2b192bc-8955-4eb4-eb66-5e1cf247267c"
      },
      "source": [
        "# 모델의 Flow 확인\r\n",
        "from IPython.display import SVG\r\n",
        "from keras.utils import model_to_dot\r\n",
        "\r\n",
        "SVG(model_to_dot(create_classify_koelectra(), dpi=65).create(prog='dot', format='svg'))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'electra.embeddings.position_ids', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']\n",
            "- This IS expected if you are initializing TFElectraModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFElectraModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFElectraModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"172pt\" viewBox=\"0.00 0.00 557.00 191.00\" width=\"503pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(.9028 .9028) rotate(0) translate(4 187)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-187 553,-187 553,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140408298416000 -->\n<g class=\"node\" id=\"node1\">\n<title>140408298416000</title>\n<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 179,-182.5 179,-146.5 0,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"89.5\" y=\"-160.8\">input_word_ids: InputLayer</text>\n</g>\n<!-- 140408298426264 -->\n<g class=\"node\" id=\"node4\">\n<title>140408298426264</title>\n<polygon fill=\"none\" points=\"163.5,-73.5 163.5,-109.5 391.5,-109.5 391.5,-73.5 163.5,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-87.8\">tf_electra_model_1: TFElectraModel</text>\n</g>\n<!-- 140408298416000&#45;&gt;140408298426264 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140408298416000-&gt;140408298426264</title>\n<path d=\"M135.9719,-146.4551C161.8448,-136.4087 194.2369,-123.8309 221.5006,-113.2445\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"222.8561,-116.4728 230.9111,-109.5904 220.3223,-109.9474 222.8561,-116.4728\" stroke=\"#000000\"/>\n</g>\n<!-- 140408298416392 -->\n<g class=\"node\" id=\"node2\">\n<title>140408298416392</title>\n<polygon fill=\"none\" points=\"197,-146.5 197,-182.5 358,-182.5 358,-146.5 197,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-160.8\">input_masks: InputLayer</text>\n</g>\n<!-- 140408298416392&#45;&gt;140408298426264 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140408298416392-&gt;140408298426264</title>\n<path d=\"M277.5,-146.4551C277.5,-138.3828 277.5,-128.6764 277.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"281.0001,-119.5903 277.5,-109.5904 274.0001,-119.5904 281.0001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140413210200608 -->\n<g class=\"node\" id=\"node3\">\n<title>140413210200608</title>\n<polygon fill=\"none\" points=\"376,-146.5 376,-182.5 549,-182.5 549,-146.5 376,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"462.5\" y=\"-160.8\">input_segment: InputLayer</text>\n</g>\n<!-- 140413210200608&#45;&gt;140408298426264 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140413210200608-&gt;140408298426264</title>\n<path d=\"M416.7697,-146.4551C391.4208,-136.4525 359.7127,-123.9407 332.9576,-113.3833\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"333.9321,-110.0052 323.3454,-109.5904 331.3627,-116.5166 333.9321,-110.0052\" stroke=\"#000000\"/>\n</g>\n<!-- 140413210198648 -->\n<g class=\"node\" id=\"node5\">\n<title>140413210198648</title>\n<polygon fill=\"none\" points=\"224,-.5 224,-36.5 331,-36.5 331,-.5 224,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-14.8\">dense_1: Dense</text>\n</g>\n<!-- 140408298426264&#45;&gt;140413210198648 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140408298426264-&gt;140413210198648</title>\n<path d=\"M277.5,-73.4551C277.5,-65.3828 277.5,-55.6764 277.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"281.0001,-46.5903 277.5,-36.5904 274.0001,-46.5904 281.0001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3LWzFdDuAml"
      },
      "source": [
        "## 훈련 및 성능 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70SZBTO0-Fq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76975ea-9a35-4d95-8789-d9caac8c59c6"
      },
      "source": [
        "# TPU 실행 시\n",
        "if TPU:\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "# 함수를 strategy.scope로 묶어 줌\n",
        "  with strategy.scope():\n",
        "    classify_model = create_classify_koelectra()\n",
        "  \n",
        "  classify_model.fit(train_x, train_y, epochs=4, shuffle=True, batch_size=32, validation_data=(test_x, test_y))\n",
        "else:\n",
        "  # GPU 모드로 훈련시킬 때\n",
        "  classify_model = create_classify_koelectra()\n",
        "  \n",
        "  classify_model.fit(train_x, train_y, epochs=4, shuffle=True, batch_size=32, validation_data=(test_x, test_y))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'electra.embeddings.position_ids', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']\n",
            "- This IS expected if you are initializing TFElectraModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFElectraModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFElectraModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - ETA: 0s - loss: 1.4769 - sparse_categorical_accuracy: 0.4480"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 152s 246ms/step - loss: 1.4758 - sparse_categorical_accuracy: 0.4485 - val_loss: 0.8149 - val_sparse_categorical_accuracy: 0.7187\n",
            "Epoch 2/4\n",
            "313/313 [==============================] - 25s 78ms/step - loss: 0.6510 - sparse_categorical_accuracy: 0.7932 - val_loss: 0.6862 - val_sparse_categorical_accuracy: 0.7744\n",
            "Epoch 3/4\n",
            "313/313 [==============================] - 25s 79ms/step - loss: 0.4696 - sparse_categorical_accuracy: 0.8567 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.7772\n",
            "Epoch 4/4\n",
            "313/313 [==============================] - 25s 79ms/step - loss: 0.3669 - sparse_categorical_accuracy: 0.8860 - val_loss: 0.6415 - val_sparse_categorical_accuracy: 0.8025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZA0_AFau4lRG"
      },
      "source": [
        "훈련한 모델을 path에 저장\n",
        "path는 임의로 지정해 주세요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBOdOlBT8K6l"
      },
      "source": [
        "# PATH는 임의로 지정\n",
        "path = \"/content\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syqCPgVa_sKZ"
      },
      "source": [
        "classify_model.save_weights(path+\"/huggingface_koelectra_classify.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1Gv3m_34nIX"
      },
      "source": [
        "훈련 모델의 예측 성능을 F1 SCORE로 체크하기 위한 작업"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjv6RMR1jYIe"
      },
      "source": [
        "def predict_convert_data(data_df):\n",
        "    global tokenizer\n",
        "    tokens, masks, segments = [], [], []\n",
        "    \n",
        "    for i in tqdm(range(len(data_df))):\n",
        "\n",
        "        token = tokenizer.encode(data_df[DATA_COLUMN][i], max_length=SEQ_LEN, truncation=True, padding='max_length')\n",
        "        num_zeros = token.count(0)\n",
        "        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\n",
        "        segment = [0]*SEQ_LEN\n",
        "\n",
        "        tokens.append(token)\n",
        "        segments.append(segment)\n",
        "        masks.append(mask)\n",
        "\n",
        "    tokens = np.array(tokens)\n",
        "    masks = np.array(masks)\n",
        "    segments = np.array(segments)\n",
        "    return [tokens, masks, segments]\n",
        "\n",
        "# 위에 정의한 convert_data 함수를 불러오는 함수를 정의\n",
        "def predict_load_data(pandas_dataframe):\n",
        "    data_df = pandas_dataframe\n",
        "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
        "    data_x = predict_convert_data(data_df)\n",
        "    return data_x"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nyqBoQD4tz1"
      },
      "source": [
        "test 데이터 예측하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzlfYX6xlFEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c501ef98-8ce1-4a20-89c5-77b3f5b4ffa0"
      },
      "source": [
        "test_set = predict_load_data(test)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "100%|██████████| 1000/1000 [00:04<00:00, 222.70it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpMD9Ua_7CNX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff039190-8e60-489f-ac48-3c91fef07894"
      },
      "source": [
        "test_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[    2, 11642,    22, ...,  4139, 27436,     3],\n",
              "        [    2,  6265,  9173, ...,     0,     0,     0],\n",
              "        [    2,  9416,  4584, ...,  3240, 17328,     3],\n",
              "        ...,\n",
              "        [    2,    22,  4482, ...,  4199,  4139,     3],\n",
              "        [    2,  6257,  7913, ...,  6257,  4234,     3],\n",
              "        [    2,  6265,  9173, ...,     0,     0,     0]]),\n",
              " array([[1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 0, 0, 0]]),\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkYBo-dklM8O"
      },
      "source": [
        "with strategy.scope():\n",
        "  preds = classify_model.predict(test_set)\n",
        "  answers = [np.argmax(preds[_][0]).astype(int) for _ in range(len(preds))]"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe70yzu-nLGh",
        "outputId": "0279662d-6a63-41ff-9116-1552b4b4296d"
      },
      "source": [
        "answers[:10]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 4, 3, 3, 3, 1, 1, 1, 4, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAJxrViQ4woJ"
      },
      "source": [
        "우리가 훈련한 모델을 F1 SCORE를 바탕으로 성능 측정  \n",
        "F1 SCORE는 precision과 recall을 가중평균하여 계산합니다  \n",
        "recall은 (모델이 TRUE라고 판정한 것의 숫자)/(전체 TRUE의 숫자)  \n",
        "precision은 (진짜 TRUE) / (모델이 TRUE라고 판정한 것의 숫자)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zXTpL9alPml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95fb40f5-4204-49ec-af92-064f8956b44f"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_true = test['label']\n",
        "# F1 Score 확인\n",
        "print(classification_report(y_true, answers))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.76      0.76       148\n",
            "           1       0.67      0.80      0.73       139\n",
            "           2       0.82      0.89      0.86       168\n",
            "           3       0.80      0.84      0.82       167\n",
            "           4       0.87      0.80      0.83       161\n",
            "           5       0.92      0.79      0.85       160\n",
            "           6       0.91      0.75      0.83        57\n",
            "\n",
            "    accuracy                           0.81      1000\n",
            "   macro avg       0.82      0.80      0.81      1000\n",
            "weighted avg       0.82      0.81      0.81      1000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03mZ0D7urOl9"
      },
      "source": [
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXJNIUgCuSa7"
      },
      "source": [
        "# 실제 데이터로 실습하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U4-Xd9251W6"
      },
      "source": [
        "문장 하나 하나를 가지고 실제로 분류해보도록 하겠습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGNnQs0Tlbiv"
      },
      "source": [
        "def sentence_convert_data(data):\n",
        "    global tokenizer\n",
        "    tokens, masks, segments = [], [], []\n",
        "    token = tokenizer.encode(data, max_length=SEQ_LEN, truncation=True, padding='max_length')\n",
        "    \n",
        "    num_zeros = token.count(0) \n",
        "    mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros \n",
        "    segment = [0]*SEQ_LEN\n",
        "\n",
        "    tokens.append(token)\n",
        "    segments.append(segment)\n",
        "    masks.append(mask)\n",
        "\n",
        "    tokens = np.array(tokens)\n",
        "    masks = np.array(masks)\n",
        "    segments = np.array(segments)\n",
        "    return [tokens, masks, segments]\n",
        "\n",
        "def news_class_predict(sentence):\n",
        "    data_x = sentence_convert_data(sentence)\n",
        "    predict = classify_model.predict(data_x)\n",
        "\n",
        "    # inverse dictionary\n",
        "    inv_dic_category = {v: k for k, v in dic_category.items()}\n",
        "    print(\"[%s] 유형입니다.\" % inv_dic_category[np.argmax(predict[0][0])])"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goaRkOc6l8mL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c2deeaf-e8bf-47b2-cb8a-367b90322932"
      },
      "source": [
        "# 201222 정치 뉴스 - 문 대통령 \"권력기관 개혁 갈등, 민주주의 성숙의 계기\"\r\n",
        "news_class_predict(\"문재인 대통령이 22일 오전 국회의장과 대법원장, 헌법재판소장, 국무총리, 중앙선거관리위원장 등 5부 요인을 초청해 코로나19 백신과 권력기관 개혁, 경제와 고용, 북미대화와 남북대화 등을 주제로 대화를 나눴다.\")"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[정치] 유형입니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRpq1b-Zo3Oa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0704a4fc-53ed-421f-ab69-3e7658f23ee4"
      },
      "source": [
        "# 201222 IT 뉴스 - 삼성전자·SKT·카카오 동맹…감염 위험 알리는 AI 만든다\r\n",
        "news_class_predict(\"한국을 대표하는 정보기술(IT) 기업들이 신종 코로나바이러스 감염증(코로나19) 등 ‘팬데믹(대유행)’ 극복을 위한 인공지능(AI) 기술 개발을 위해 손잡았다. 삼성전자, SK텔레콤, 카카오는 코로나19 조기 극복과 공공 이익을 위한 AI 개발에 협력하기로 했다고 22일 발표했다. 이번 ‘AI 동맹’으로 각 사가 가진 핵심 역량을 모아 미래 AI 기술 개발과 사회적 난제 해결을 위한 AI 활용 방안 연구, AI 기술 저변 확대를 공동 추진한다.\")"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[IT과학] 유형입니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX6aA3NPuVuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccad57d8-5f92-4053-9095-b1e3c3c107b4"
      },
      "source": [
        "# 201222 경제 뉴스 - 이건희 주식 상속세 11조400억원 확정…두 달새 8000억원 늘어\r\n",
        "news_class_predict(\"고(故) 이건희 삼성전자 회장이 보유한 주식에 대해 이재용 삼성전자 부회장 등 상속인이 내야할 상속세 규모가 약 11조400억 원으로 확정됐다. 역대 최대 규모다. 이 부회장을 비롯해 유가족들의 상속세 재원 마련 방안에 대한 재계 관심이 높아지고 있다. 이 회장이 보유하고 있는 주식은 삼성전자(4.18%·2억4927만3200주), 삼성전자 우선주(0.08%·61만9900주), 삼성생명(20.76%·4151만9180주), 삼성물산(2.88%·542만 5733주), 삼성SDS(0.01%·9701주) 등이다.\")"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[경제] 유형입니다.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}