{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_LSTM_MLP_CNN_RCNN_Draft_Preprocess.ipynb",
      "provenance": [],
      "mount_file_id": "1Ho7T2ZBZapxDdrqT8Es-LZm0PQrGonOQ",
      "authorship_tag": "ABX9TyPbBIo7yfH2oaABW0UjayQT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guard1000/NLP_MCC/blob/master/4_LSTM_MLP_CNN_RCNN_Draft_Preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNKFyBg1Syzc",
        "colab_type": "text"
      },
      "source": [
        "환경: 구글 Colab\n",
        "\n",
        "데이터: 크롤러로 긁은 네이버 뉴스 2019.01 ~ 2019.04\n",
        "-- 7만개 좀 넘는데 미니 데이터로 1만개만 사용\n",
        "\n",
        "\n",
        "\n",
        "[Contents]\n",
        "0. 데이터 수집\n",
        "1. 형태소 분석\n",
        "2. Tokenizer로 인코딩\n",
        "3. 희소 단어 배제\n",
        "4. 불필요 행 제거\n",
        "5. 기사 길이 분포 확인 및 적정 길이로 패딩\n",
        "6. 모델 제작 - LSTM, MLP, CNN, RCNN\n",
        "7. Test\n",
        "\n",
        "\n",
        "[결론]\n",
        "\n",
        "생각보다 별로네...\n",
        "\n",
        "전처리를 잘 해보자\n",
        "\n",
        "다시 해보기."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygp3PwDvOJ-3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "outputId": "0a728132-971d-47b8-a46a-4bb8266db30c"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 234kB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.17.5)\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/36/1b/2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec/tweepy-3.8.0-py2.py3-none-any.whl\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/3c/1dbe5d6943b5c68e8df17c8b3a05db4725eadb5c7b7de437506aa3030701/JPype1-0.7.2-cp36-cp36m-manylinux1_x86_64.whl (2.4MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4MB 36.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.21.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2019.11.28)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: beautifulsoup4, tweepy, colorama, JPype1, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-0.7.2 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrrKJDwaOUuA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "e8cec06f-e8d3-480f-a81f-04b7ae651ea2"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from konlpy.tag import Okt\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import re"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Njf0g19OtQ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "ffc24cf7-b270-431c-9115-c39fe27c3a78"
      },
      "source": [
        "# 수집해둔 데이터 불러오기.\n",
        "# 수집과정은 ~~~~~~~~~ 참고.\n",
        "df = pd.read_csv(\"/content/drive/My Drive/data/Article_shuffled.csv\")\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>이해찬 민주당 단배식서 내년 총선 압승해 민주주의 정착 새해 첫날인 1일 여권은 집권 3년 차를 맞은 문재인 정부의 성공을 기원하며 내부 결속 의지를 다졌다. 특히 여당인 더불어민주당은 2020년 총선 압승 을 발판으로 2022년 정권 재창출 을 이뤄내겠다고 다짐했다. 문희상 국회의장은 이날 서울 한남동 의장 공관에서 신년 기자간담회를 열고 집권 3년 차는 아주 중요한 전기 라고 했다. 그러면서 올해를 황금돼지해라고 부르는데 저는 검은 돼지든 흰 돼지든 무게만 나가면 된다고 생각한다 며 흑돈백돈 黑豚白豚 론 을 펼쳤다. 중국 덩샤오핑의 흑묘백묘론 검은 고양이든 흰 고양이든 쥐만 잘 잡으면 된다 을 차용해 올해 경제 발전이 가장 중요한 과제라는 점을 강조한 것으로 해석됐다. 문 의장은 황금으로 누런 돼지라고 하면 이건 정말 대박 이라며 번영의 돼지해에 문재인 정부도 성공하고 우리도 성공하는 한 해가 되길 바란다 고 했다. 민주당은 이날 여의도 당사에서 신년인사회를 겸한 단배식을 열었다. 이해찬 대표는 재작년에는 정권 교체를 이뤘고 작년에는 지방선거에서 민주당이 압도적 승리를 거뒀다 며 이것을 기반으로 내년 총선에서 아주 크게 압승하는 정치적 성과를 올려야 한다 고 했다. 이 대표는 총선에서 크게 이기는 게 이 나라 민주주의를 정착시키는 데 아주 중요한 과업 이라며 그래야 2022년 대선에서 정권을 재창출해 민주당이 평화와 민주주의를 지키는 마지막 보루가 될 수 있다 고 했다. 이 대표는 남북 관계와 관련해 지난해 70년 분단 체제에서 평화 체제로 전환되는 역사적 한 획을 그었다 며 아마 남북 정상회담이 올해 일찍 열릴 가능성이 크다 고 했다. 경제 문제에 대해선 어렵다곤 하지만 조금씩은 나아지고 있다 고 했다. 그러자 홍영표 원내대표는 맞바람을 향해 돛을 펼친다 는 역풍장범 逆風張帆 이라는 말이 있다 며 앞으로도 많은 시련과 도전이 기다리고 있다. 이 대표를 중심으로 더욱 단결하는 한 해가 되도록 하자 고 했다. 민주당 지도부는 이날 오전 서울 국립현충원에서 김영삼·김대중 전 대통령 묘역을 참배했다. 이어 이승만·박정희 전 대통령 묘역도 찾았으나 일부 시민이 어떻게 박 전 대통령 묘역에 인사할 수 있나. 부끄럽지도 않으냐 고 항의해 분위기가 일순간 얼어붙기도 했다. 오후에는 경남 김해 봉하마을을 방문해 노무현 전 대통령 묘역을 참배했다.</th>\n",
              "      <th>정치</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>지난해 서울 아파트값이 2006년 이후 가장 큰 폭으로 상승했습니다. 2일 한국감정...</td>\n",
              "      <td>경제</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>의왕 연합뉴스 김인유 기자 경기 의왕시는 경로당 어르신들의 건강을 전문적으로 돌보는...</td>\n",
              "      <td>생활문화</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>한민수 기자 이번에 샌프란시스코에서 선언할 것은 직접판매 체계의 구축입니다. 지난해...</td>\n",
              "      <td>IT과학</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>JTBC ‘2019년 한국 어디로 가나’ 신년 토론. 사진 JTBC 방송화면 캡처 ...</td>\n",
              "      <td>정치</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>고려대 온라인 커뮤니티 고파스에 올라온 손혜원 더불어민주당 의원에 18원의 후원금을...</td>\n",
              "      <td>정치</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  이해찬 민주당 단배식서 내년 총선 압승해 민주주의 정착 새해 첫날인 1일 여권은 집권 3년 차를 맞은 문재인 정부의 성공을 기원하며 내부 결속 의지를 다졌다. 특히 여당인 더불어민주당은 2020년 총선 압승 을 발판으로 2022년 정권 재창출 을 이뤄내겠다고 다짐했다. 문희상 국회의장은 이날 서울 한남동 의장 공관에서 신년 기자간담회를 열고 집권 3년 차는 아주 중요한 전기 라고 했다. 그러면서 올해를 황금돼지해라고 부르는데 저는 검은 돼지든 흰 돼지든 무게만 나가면 된다고 생각한다 며 흑돈백돈 黑豚白豚 론 을 펼쳤다. 중국 덩샤오핑의 흑묘백묘론 검은 고양이든 흰 고양이든 쥐만 잘 잡으면 된다 을 차용해 올해 경제 발전이 가장 중요한 과제라는 점을 강조한 것으로 해석됐다. 문 의장은 황금으로 누런 돼지라고 하면 이건 정말 대박 이라며 번영의 돼지해에 문재인 정부도 성공하고 우리도 성공하는 한 해가 되길 바란다 고 했다. 민주당은 이날 여의도 당사에서 신년인사회를 겸한 단배식을 열었다. 이해찬 대표는 재작년에는 정권 교체를 이뤘고 작년에는 지방선거에서 민주당이 압도적 승리를 거뒀다 며 이것을 기반으로 내년 총선에서 아주 크게 압승하는 정치적 성과를 올려야 한다 고 했다. 이 대표는 총선에서 크게 이기는 게 이 나라 민주주의를 정착시키는 데 아주 중요한 과업 이라며 그래야 2022년 대선에서 정권을 재창출해 민주당이 평화와 민주주의를 지키는 마지막 보루가 될 수 있다 고 했다. 이 대표는 남북 관계와 관련해 지난해 70년 분단 체제에서 평화 체제로 전환되는 역사적 한 획을 그었다 며 아마 남북 정상회담이 올해 일찍 열릴 가능성이 크다 고 했다. 경제 문제에 대해선 어렵다곤 하지만 조금씩은 나아지고 있다 고 했다. 그러자 홍영표 원내대표는 맞바람을 향해 돛을 펼친다 는 역풍장범 逆風張帆 이라는 말이 있다 며 앞으로도 많은 시련과 도전이 기다리고 있다. 이 대표를 중심으로 더욱 단결하는 한 해가 되도록 하자 고 했다. 민주당 지도부는 이날 오전 서울 국립현충원에서 김영삼·김대중 전 대통령 묘역을 참배했다. 이어 이승만·박정희 전 대통령 묘역도 찾았으나 일부 시민이 어떻게 박 전 대통령 묘역에 인사할 수 있나. 부끄럽지도 않으냐 고 항의해 분위기가 일순간 얼어붙기도 했다. 오후에는 경남 김해 봉하마을을 방문해 노무현 전 대통령 묘역을 참배했다.    정치\n",
              "0  지난해 서울 아파트값이 2006년 이후 가장 큰 폭으로 상승했습니다. 2일 한국감정...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       경제\n",
              "1  의왕 연합뉴스 김인유 기자 경기 의왕시는 경로당 어르신들의 건강을 전문적으로 돌보는...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     생활문화\n",
              "2  한민수 기자 이번에 샌프란시스코에서 선언할 것은 직접판매 체계의 구축입니다. 지난해...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     IT과학\n",
              "3  JTBC ‘2019년 한국 어디로 가나’ 신년 토론. 사진 JTBC 방송화면 캡처 ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       정치\n",
              "4  고려대 온라인 커뮤니티 고파스에 올라온 손혜원 더불어민주당 의원에 18원의 후원금을...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       정치"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2mTul6wPtdN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "56bac2e7-eced-4cf8-8384-450308e0c8a7"
      },
      "source": [
        "df.iloc[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "이해찬 민주당 단배식서 내년 총선 압승해 민주주의 정착 새해 첫날인 1일 여권은 집권 3년 차를 맞은 문재인 정부의 성공을 기원하며 내부 결속 의지를 다졌다. 특히 여당인 더불어민주당은 2020년 총선 압승 을 발판으로 2022년 정권 재창출 을 이뤄내겠다고 다짐했다. 문희상 국회의장은 이날 서울 한남동 의장 공관에서 신년 기자간담회를 열고 집권 3년 차는 아주 중요한 전기 라고 했다. 그러면서 올해를 황금돼지해라고 부르는데 저는 검은 돼지든 흰 돼지든 무게만 나가면 된다고 생각한다 며 흑돈백돈 黑豚白豚 론 을 펼쳤다. 중국 덩샤오핑의 흑묘백묘론 검은 고양이든 흰 고양이든 쥐만 잘 잡으면 된다 을 차용해 올해 경제 발전이 가장 중요한 과제라는 점을 강조한 것으로 해석됐다. 문 의장은 황금으로 누런 돼지라고 하면 이건 정말 대박 이라며 번영의 돼지해에 문재인 정부도 성공하고 우리도 성공하는 한 해가 되길 바란다 고 했다. 민주당은 이날 여의도 당사에서 신년인사회를 겸한 단배식을 열었다. 이해찬 대표는 재작년에는 정권 교체를 이뤘고 작년에는 지방선거에서 민주당이 압도적 승리를 거뒀다 며 이것을 기반으로 내년 총선에서 아주 크게 압승하는 정치적 성과를 올려야 한다 고 했다. 이 대표는 총선에서 크게 이기는 게 이 나라 민주주의를 정착시키는 데 아주 중요한 과업 이라며 그래야 2022년 대선에서 정권을 재창출해 민주당이 평화와 민주주의를 지키는 마지막 보루가 될 수 있다 고 했다. 이 대표는 남북 관계와 관련해 지난해 70년 분단 체제에서 평화 체제로 전환되는 역사적 한 획을 그었다 며 아마 남북 정상회담이 올해 일찍 열릴 가능성이 크다 고 했다. 경제 문제에 대해선 어렵다곤 하지만 조금씩은 나아지고 있다 고 했다. 그러자 홍영표 원내대표는 맞바람을 향해 돛을 펼친다 는 역풍장범 逆風張帆 이라는 말이 있다 며 앞으로도 많은 시련과 도전이 기다리고 있다. 이 대표를 중심으로 더욱 단결하는 한 해가 되도록 하자 고 했다. 민주당 지도부는 이날 오전 서울 국립현충원에서 김영삼·김대중 전 대통령 묘역을 참배했다. 이어 이승만·박정희 전 대통령 묘역도 찾았으나 일부 시민이 어떻게 박 전 대통령 묘역에 인사할 수 있나. 부끄럽지도 않으냐 고 항의해 분위기가 일순간 얼어붙기도 했다. 오후에는 경남 김해 봉하마을을 방문해 노무현 전 대통령 묘역을 참배했다.    지난해 서울 아파트값이 2006년 이후 가장 큰 폭으로 상승했습니다. 2일 한국감정...\n",
              "정치                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      경제\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOygaJG1O3rS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "9292abe3-e523-4bf2-a2b4-5768b4b8ad32"
      },
      "source": [
        "# Column 명 바꿔주기\n",
        "df.rename(columns={'이해찬 민주당 단배식서 내년 총선 압승해 민주주의 정착 새해 첫날인 1일 여권은 집권 3년 차를 맞은 문재인 정부의 성공을 기원하며 내부 결속 의지를 다졌다. 특히 여당인 더불어민주당은 2020년 총선 압승 을 발판으로 2022년 정권 재창출 을 이뤄내겠다고 다짐했다. 문희상 국회의장은 이날 서울 한남동 의장 공관에서 신년 기자간담회를 열고 집권 3년 차는 아주 중요한 전기 라고 했다. 그러면서 올해를 황금돼지해라고 부르는데 저는 검은 돼지든 흰 돼지든 무게만 나가면 된다고 생각한다 며 흑돈백돈 黑豚白豚 론 을 펼쳤다. 중국 덩샤오핑의 흑묘백묘론 검은 고양이든 흰 고양이든 쥐만 잘 잡으면 된다 을 차용해 올해 경제 발전이 가장 중요한 과제라는 점을 강조한 것으로 해석됐다. 문 의장은 황금으로 누런 돼지라고 하면 이건 정말 대박 이라며 번영의 돼지해에 문재인 정부도 성공하고 우리도 성공하는 한 해가 되길 바란다 고 했다. 민주당은 이날 여의도 당사에서 신년인사회를 겸한 단배식을 열었다. 이해찬 대표는 재작년에는 정권 교체를 이뤘고 작년에는 지방선거에서 민주당이 압도적 승리를 거뒀다 며 이것을 기반으로 내년 총선에서 아주 크게 압승하는 정치적 성과를 올려야 한다 고 했다. 이 대표는 총선에서 크게 이기는 게 이 나라 민주주의를 정착시키는 데 아주 중요한 과업 이라며 그래야 2022년 대선에서 정권을 재창출해 민주당이 평화와 민주주의를 지키는 마지막 보루가 될 수 있다 고 했다. 이 대표는 남북 관계와 관련해 지난해 70년 분단 체제에서 평화 체제로 전환되는 역사적 한 획을 그었다 며 아마 남북 정상회담이 올해 일찍 열릴 가능성이 크다 고 했다. 경제 문제에 대해선 어렵다곤 하지만 조금씩은 나아지고 있다 고 했다. 그러자 홍영표 원내대표는 맞바람을 향해 돛을 펼친다 는 역풍장범 逆風張帆 이라는 말이 있다 며 앞으로도 많은 시련과 도전이 기다리고 있다. 이 대표를 중심으로 더욱 단결하는 한 해가 되도록 하자 고 했다. 민주당 지도부는 이날 오전 서울 국립현충원에서 김영삼·김대중 전 대통령 묘역을 참배했다. 이어 이승만·박정희 전 대통령 묘역도 찾았으나 일부 시민이 어떻게 박 전 대통령 묘역에 인사할 수 있나. 부끄럽지도 않으냐 고 항의해 분위기가 일순간 얼어붙기도 했다. 오후에는 경남 김해 봉하마을을 방문해 노무현 전 대통령 묘역을 참배했다.' : 'Query', '정치': 'GT'}, inplace=True)\n",
        "\n",
        "# 10000개만 띠어내서 train_data 생성\n",
        "train_data = df.iloc[:10000]\n",
        "print(train_data.shape)\n",
        "\n",
        "# 1000개로 테스트 데이터\n",
        "test_data = df.iloc[10000:11000]\n",
        "print(test_data.shape)\n",
        "\n",
        "display(train_data.head())\n",
        "display(test_data.head())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 2)\n",
            "(1000, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Query</th>\n",
              "      <th>GT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>지난해 서울 아파트값이 2006년 이후 가장 큰 폭으로 상승했습니다. 2일 한국감정...</td>\n",
              "      <td>경제</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>의왕 연합뉴스 김인유 기자 경기 의왕시는 경로당 어르신들의 건강을 전문적으로 돌보는...</td>\n",
              "      <td>생활문화</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>한민수 기자 이번에 샌프란시스코에서 선언할 것은 직접판매 체계의 구축입니다. 지난해...</td>\n",
              "      <td>IT과학</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>JTBC ‘2019년 한국 어디로 가나’ 신년 토론. 사진 JTBC 방송화면 캡처 ...</td>\n",
              "      <td>정치</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>고려대 온라인 커뮤니티 고파스에 올라온 손혜원 더불어민주당 의원에 18원의 후원금을...</td>\n",
              "      <td>정치</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Query    GT\n",
              "0  지난해 서울 아파트값이 2006년 이후 가장 큰 폭으로 상승했습니다. 2일 한국감정...    경제\n",
              "1  의왕 연합뉴스 김인유 기자 경기 의왕시는 경로당 어르신들의 건강을 전문적으로 돌보는...  생활문화\n",
              "2  한민수 기자 이번에 샌프란시스코에서 선언할 것은 직접판매 체계의 구축입니다. 지난해...  IT과학\n",
              "3  JTBC ‘2019년 한국 어디로 가나’ 신년 토론. 사진 JTBC 방송화면 캡처 ...    정치\n",
              "4  고려대 온라인 커뮤니티 고파스에 올라온 손혜원 더불어민주당 의원에 18원의 후원금을...    정치"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Query</th>\n",
              "      <th>GT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10000</th>\n",
              "      <td>내달 2일 남성약물 카르텔 규탄시위 주최측 인터뷰 약물 사고파는 이들뿐 아니라 방관...</td>\n",
              "      <td>오피니언</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10001</th>\n",
              "      <td>서울 뉴시스 추상철 기자 상장폐지가 결정된경남제약의 소액주주모임이 2일 오전 서울 ...</td>\n",
              "      <td>사회</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10002</th>\n",
              "      <td>조명균 통일부 장관 연합뉴스 자료사진 서울 연합뉴스 이상현 기자 조명균 통일부 장관...</td>\n",
              "      <td>사회</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10003</th>\n",
              "      <td>이데일리 신태현 기자 김병준 자유한국당 비상대책위원장 나경원 원내대표 등이 2일 서...</td>\n",
              "      <td>정치</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10004</th>\n",
              "      <td>김태년 더불어민주당 정책위의장 연합뉴스 김태년 더불어민주당 정책위의장은 3일 서울 ...</td>\n",
              "      <td>정치</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Query    GT\n",
              "10000  내달 2일 남성약물 카르텔 규탄시위 주최측 인터뷰 약물 사고파는 이들뿐 아니라 방관...  오피니언\n",
              "10001  서울 뉴시스 추상철 기자 상장폐지가 결정된경남제약의 소액주주모임이 2일 오전 서울 ...    사회\n",
              "10002  조명균 통일부 장관 연합뉴스 자료사진 서울 연합뉴스 이상현 기자 조명균 통일부 장관...    사회\n",
              "10003  이데일리 신태현 기자 김병준 자유한국당 비상대책위원장 나경원 원내대표 등이 2일 서...    정치\n",
              "10004  김태년 더불어민주당 정책위의장 연합뉴스 김태년 더불어민주당 정책위의장은 3일 서울 ...    정치"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bet_1LftQsXI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ac7bac29-c784-4ea0-b1d8-b04d579f1cad"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize = (8,6))\n",
        "train_data.groupby('GT').Query.count().plot.bar(ylim=0)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f71b9ccb320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 44284 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 54617 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 44221 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 51228 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 49324 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 54924 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 49373 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 54876 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 47928 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 54868 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 49464 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 44228 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 50724 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 54588 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 45768 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 50616 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 51221 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 52824 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 44284 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 54617 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 44221 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 51228 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 49324 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 54924 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 49373 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 54876 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 47928 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 54868 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 49464 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 44228 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 50724 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 54588 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 45768 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 50616 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 51221 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 52824 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAGBCAYAAABLgunaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFSe7QXMQ3pw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a0ee6459-c3ae-4978-ccc7-f78ec5283210"
      },
      "source": [
        "# 형태소 분석\n",
        "okt = Okt()\n",
        "stopwords = ['의','기자', '”', '“', '며','그', '가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
        "\n",
        "X_train = []\n",
        "X_test = []\n",
        "\n",
        "# X_train 10000개, X_test 1000개\n",
        "for i in range(len(train_data) + len(test_data)):\n",
        "  sentence = okt.pos(df.iloc[i].Query, norm=True, stem=True)\n",
        "  temp = []\n",
        "  temp_embedding = []\n",
        "  all_temp = []\n",
        "  for k in range(len(sentence)):\n",
        "    temp_embedding.append(sentence[k][0])\n",
        "    #if sentence[k][1] in [\"Noun\"]:  # 명사만 써보고 싶을땐 이거\n",
        "    if sentence[k][1] not in [\"Josa\", \"Eomi\", \"Punctuation\", \"Suffix\"] and sentence[k][0] not in stopwords: \n",
        "      temp.append(sentence[k][0]) #+ '/' + sentence[k][1])\n",
        "  all_temp.append(temp)\n",
        "\n",
        "  if i < len(train_data):\n",
        "    train_data.iloc[i].Query = ' '.join(all_temp[0])\n",
        "    X_train.append(all_temp[0])\n",
        "  else:\n",
        "    test_data.iloc[i-len(train_data)].Query = ' '.join(all_temp[0])\n",
        "    X_test.append(all_temp[0])\n",
        "\n",
        "train_data.head()\n",
        "test_data.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Query</th>\n",
              "      <th>GT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10000</th>\n",
              "      <td>내달 2일 남성 약물 카르텔 규탄 시위 주최 인터뷰 약물 사고팔다 뿐 아니다 방관 ...</td>\n",
              "      <td>오피니언</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10001</th>\n",
              "      <td>서울 뉴시스 추상 철 상장폐지 결정 되다 경남 제약 소액 주 주 모임 2일 오전 서...</td>\n",
              "      <td>사회</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10002</th>\n",
              "      <td>조명 균 통일부 장관 연합뉴스 자료 사진 서울 연합뉴스 이상현 조명 균 통일부 장관...</td>\n",
              "      <td>사회</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10003</th>\n",
              "      <td>이데일리 신 태현 김병준 자유 한국 비상 대책 위원장 나경원 원내대표 등 2일 서울...</td>\n",
              "      <td>정치</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10004</th>\n",
              "      <td>김태년 더불다 민주당 정책 위 의장 연합뉴스 김태년 더불다 민주당 정책 위 의장 3...</td>\n",
              "      <td>정치</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Query    GT\n",
              "10000  내달 2일 남성 약물 카르텔 규탄 시위 주최 인터뷰 약물 사고팔다 뿐 아니다 방관 ...  오피니언\n",
              "10001  서울 뉴시스 추상 철 상장폐지 결정 되다 경남 제약 소액 주 주 모임 2일 오전 서...    사회\n",
              "10002  조명 균 통일부 장관 연합뉴스 자료 사진 서울 연합뉴스 이상현 조명 균 통일부 장관...    사회\n",
              "10003  이데일리 신 태현 김병준 자유 한국 비상 대책 위원장 나경원 원내대표 등 2일 서울...    정치\n",
              "10004  김태년 더불다 민주당 정책 위 의장 연합뉴스 김태년 더불다 민주당 정책 위 의장 3...    정치"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4rBINo7Sx5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 형태소로 나눠준 데이터 저장하고 싶다면!\n",
        "train_data.to_csv(\"/content/drive/My Drive/data/train_data.csv\", index = False)\n",
        "test_data.to_csv(\"/content/drive/My Drive/data/test_data.csv\", index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngX52-1-eral",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ca92ef7-fb06-4511-a432-dc1c5dc45289"
      },
      "source": [
        "# Tokenizer로 정수 인코딩\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "tokenizer.word_index"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'있다': 1,\n",
              " '되다': 2,\n",
              " '것': 3,\n",
              " '수': 4,\n",
              " '등': 5,\n",
              " '‘': 6,\n",
              " '이다': 7,\n",
              " '고': 8,\n",
              " '않다': 9,\n",
              " '전': 10,\n",
              " '돼다': 11,\n",
              " '없다': 12,\n",
              " '말': 13,\n",
              " '서울': 14,\n",
              " '1': 15,\n",
              " '한국': 16,\n",
              " '위': 17,\n",
              " '받다': 18,\n",
              " '정부': 19,\n",
              " '미국': 20,\n",
              " '대통령': 21,\n",
              " '아니다': 22,\n",
              " '보다': 23,\n",
              " '늘다': 24,\n",
              " '대한': 25,\n",
              " '사업': 26,\n",
              " '밝히다': 27,\n",
              " '통해': 28,\n",
              " '지난해': 29,\n",
              " '오다': 30,\n",
              " '가다': 31,\n",
              " '우리': 32,\n",
              " '위해': 33,\n",
              " '기업': 34,\n",
              " '경제': 35,\n",
              " '기술': 36,\n",
              " '제': 37,\n",
              " '다': 38,\n",
              " '더': 39,\n",
              " '2': 40,\n",
              " '3': 41,\n",
              " '시장': 42,\n",
              " '따르다': 43,\n",
              " '중': 44,\n",
              " '올해': 45,\n",
              " '내': 46,\n",
              " '대표': 47,\n",
              " '중국': 48,\n",
              " '때': 49,\n",
              " '같다': 50,\n",
              " '일': 51,\n",
              " '명': 52,\n",
              " '사람': 53,\n",
              " '크다': 54,\n",
              " '및': 55,\n",
              " '못': 56,\n",
              " '5': 57,\n",
              " '함께': 58,\n",
              " '만들다': 59,\n",
              " '개': 60,\n",
              " '북한': 61,\n",
              " '지역': 62,\n",
              " '문제': 63,\n",
              " '서비스': 64,\n",
              " '때문': 65,\n",
              " '많다': 66,\n",
              " '대해': 67,\n",
              " '사회': 68,\n",
              " '관련': 69,\n",
              " '세계': 70,\n",
              " '기': 71,\n",
              " '대': 72,\n",
              " '날': 73,\n",
              " '그렇다': 74,\n",
              " '새롭다': 75,\n",
              " '제공': 76,\n",
              " '정책': 77,\n",
              " '2일': 78,\n",
              " '로': 79,\n",
              " '새해': 80,\n",
              " '열리다': 81,\n",
              " '이번': 82,\n",
              " '나오다': 83,\n",
              " '김': 84,\n",
              " '산업': 85,\n",
              " '4': 86,\n",
              " '지난': 87,\n",
              " '이르다': 88,\n",
              " '또': 89,\n",
              " '시간': 90,\n",
              " '차': 91,\n",
              " '신': 92,\n",
              " '지원': 93,\n",
              " '점': 94,\n",
              " '들다': 95,\n",
              " '개발': 96,\n",
              " '안': 97,\n",
              " '주': 98,\n",
              " '투자': 99,\n",
              " '시작': 100,\n",
              " '사진': 101,\n",
              " '국내': 102,\n",
              " '시': 103,\n",
              " '국민': 104,\n",
              " '대다': 105,\n",
              " '의원': 106,\n",
              " '보이다': 107,\n",
              " '이상': 108,\n",
              " '경우': 109,\n",
              " '계획': 110,\n",
              " '문': 111,\n",
              " '가장': 112,\n",
              " '생각': 113,\n",
              " '성장': 114,\n",
              " '이후': 115,\n",
              " '전자': 116,\n",
              " '혁신': 117,\n",
              " '진행': 118,\n",
              " '연합뉴스': 119,\n",
              " '달': 120,\n",
              " '2019년': 121,\n",
              " '해': 122,\n",
              " '세': 123,\n",
              " '라며': 124,\n",
              " '상황': 125,\n",
              " '시키다': 126,\n",
              " '국가': 127,\n",
              " '미래': 128,\n",
              " '위원장': 129,\n",
              " '경': 130,\n",
              " '높다': 131,\n",
              " '일본': 132,\n",
              " '좋다': 133,\n",
              " '추진': 134,\n",
              " '최근': 135,\n",
              " '이렇다': 136,\n",
              " '두': 137,\n",
              " '문화': 138,\n",
              " '연': 139,\n",
              " '다양하다': 140,\n",
              " '강조': 141,\n",
              " '원': 142,\n",
              " '청와대': 143,\n",
              " '곳': 144,\n",
              " '1일': 145,\n",
              " '모두': 146,\n",
              " '발표': 147,\n",
              " '오전': 148,\n",
              " '현재': 149,\n",
              " '뒤': 150,\n",
              " '간': 151,\n",
              " '설명': 152,\n",
              " '사': 153,\n",
              " '다른': 154,\n",
              " '하지만': 155,\n",
              " '운영': 156,\n",
              " '부터': 157,\n",
              " '지금': 158,\n",
              " '맞다': 159,\n",
              " '내다': 160,\n",
              " '자신': 161,\n",
              " '신년사': 162,\n",
              " '회': 163,\n",
              " 'g': 164,\n",
              " '어떻다': 165,\n",
              " '뉴스': 166,\n",
              " '성': 167,\n",
              " '사실': 168,\n",
              " '첫': 169,\n",
              " '특히': 170,\n",
              " '데': 171,\n",
              " '앞': 172,\n",
              " 'lg': 173,\n",
              " '글로벌': 174,\n",
              " '확대': 175,\n",
              " '후': 176,\n",
              " '고객': 177,\n",
              " '공개': 178,\n",
              " '주장': 179,\n",
              " '회장': 180,\n",
              " '평가': 181,\n",
              " '속': 182,\n",
              " '필요하다': 183,\n",
              " '사용': 184,\n",
              " '전망': 185,\n",
              " '예정': 186,\n",
              " '트럼프': 187,\n",
              " '3일': 188,\n",
              " '밉다': 189,\n",
              " '저': 190,\n",
              " '결과': 191,\n",
              " '임': 192,\n",
              " '게': 193,\n",
              " '오후': 194,\n",
              " '제품': 195,\n",
              " '공': 196,\n",
              " '되어다': 197,\n",
              " '나': 198,\n",
              " '구': 199,\n",
              " '기록': 200,\n",
              " '민주당': 201,\n",
              " '센터': 202,\n",
              " '조사': 203,\n",
              " '분야': 204,\n",
              " '분석': 205,\n",
              " '가능하다': 206,\n",
              " '변화': 207,\n",
              " '환경': 208,\n",
              " '시민': 209,\n",
              " '찾다': 210,\n",
              " '교수': 211,\n",
              " '게임': 212,\n",
              " '나가다': 213,\n",
              " '수준': 214,\n",
              " '그룹': 215,\n",
              " '정도': 216,\n",
              " '건': 217,\n",
              " '주다': 218,\n",
              " '금융': 219,\n",
              " '최대': 220,\n",
              " '발생': 221,\n",
              " '판매': 222,\n",
              " '정보': 223,\n",
              " '자다': 224,\n",
              " 'tv': 225,\n",
              " '모든': 226,\n",
              " '위원회': 227,\n",
              " '국회': 228,\n",
              " '뉴시스': 229,\n",
              " '관계자': 230,\n",
              " '대상': 231,\n",
              " '6': 232,\n",
              " '문재인': 233,\n",
              " '관리': 234,\n",
              " '씨': 235,\n",
              " '조': 236,\n",
              " '여': 237,\n",
              " '현지': 238,\n",
              " '활용': 239,\n",
              " '지': 240,\n",
              " '이용': 241,\n",
              " '법': 242,\n",
              " '기반': 243,\n",
              " '업체': 244,\n",
              " '직원': 245,\n",
              " '증가': 246,\n",
              " '평화': 247,\n",
              " '10': 248,\n",
              " '과정': 249,\n",
              " '한다는': 250,\n",
              " '시스템': 251,\n",
              " '회사': 252,\n",
              " '약': 253,\n",
              " '내용': 254,\n",
              " '기존': 255,\n",
              " '발전': 256,\n",
              " '대비': 257,\n",
              " '행사': 258,\n",
              " '최고': 259,\n",
              " '규제': 260,\n",
              " '이유': 261,\n",
              " '총': 262,\n",
              " '까지': 263,\n",
              " '가운데': 264,\n",
              " '다시': 265,\n",
              " '어렵다': 266,\n",
              " '기준': 267,\n",
              " '2017년': 268,\n",
              " '제도': 269,\n",
              " '마련': 270,\n",
              " '전략': 271,\n",
              " '가능성': 272,\n",
              " '비': 273,\n",
              " '삼성': 274,\n",
              " '사장': 275,\n",
              " '나서다': 276,\n",
              " '지속': 277,\n",
              " '하나': 278,\n",
              " '2019': 279,\n",
              " '인사': 280,\n",
              " '정치': 281,\n",
              " '모습': 282,\n",
              " '서다': 283,\n",
              " '규모': 284,\n",
              " '자유': 285,\n",
              " '참여': 286,\n",
              " 'ai': 287,\n",
              " '관': 288,\n",
              " '자동차': 289,\n",
              " '장관': 290,\n",
              " '가지': 291,\n",
              " '선': 292,\n",
              " '노력': 293,\n",
              " '입장': 294,\n",
              " '거래': 295,\n",
              " '없이': 296,\n",
              " '방송': 297,\n",
              " '12월': 298,\n",
              " '그러나': 299,\n",
              " '시대': 300,\n",
              " '당시': 301,\n",
              " '방식': 302,\n",
              " '넘다': 303,\n",
              " '소': 304,\n",
              " '관계': 305,\n",
              " '확인': 306,\n",
              " '활동': 307,\n",
              " 'sk': 308,\n",
              " '요구': 309,\n",
              " '중요하다': 310,\n",
              " '처음': 311,\n",
              " '주요': 312,\n",
              " '개선': 313,\n",
              " '교육': 314,\n",
              " '중심': 315,\n",
              " '손': 316,\n",
              " '현': 317,\n",
              " '성과': 318,\n",
              " '동': 319,\n",
              " '현장': 320,\n",
              " '적용': 321,\n",
              " '업계': 322,\n",
              " '의미': 323,\n",
              " '김정은': 324,\n",
              " '협력': 325,\n",
              " '추가': 326,\n",
              " '2018년': 327,\n",
              " '전체': 328,\n",
              " '준비': 329,\n",
              " '결정': 330,\n",
              " '비핵화': 331,\n",
              " '△': 332,\n",
              " '해외': 333,\n",
              " '사건': 334,\n",
              " '생산': 335,\n",
              " '을': 336,\n",
              " '콘텐츠': 337,\n",
              " '예상': 338,\n",
              " '기관': 339,\n",
              " '1월': 340,\n",
              " '일자리': 341,\n",
              " '두다': 342,\n",
              " '추다': 343,\n",
              " '전국': 344,\n",
              " '출시': 345,\n",
              " '길': 346,\n",
              " '번': 347,\n",
              " '포함': 348,\n",
              " '구축': 349,\n",
              " '경기': 350,\n",
              " '역할': 351,\n",
              " '보고': 352,\n",
              " '적극': 353,\n",
              " '수출': 354,\n",
              " '아이': 355,\n",
              " '삼': 356,\n",
              " '팀': 357,\n",
              " '직접': 358,\n",
              " '핵심': 359,\n",
              " '회의': 360,\n",
              " '플랫폼': 361,\n",
              " '병원': 362,\n",
              " '많이': 363,\n",
              " '차량': 364,\n",
              " '비롯': 365,\n",
              " '하락': 366,\n",
              " '사무관': 367,\n",
              " '지다': 368,\n",
              " '부산': 369,\n",
              " '협상': 370,\n",
              " '당': 371,\n",
              " '싶다': 372,\n",
              " '오르다': 373,\n",
              " '이어지다': 374,\n",
              " '운동': 375,\n",
              " '가격': 376,\n",
              " '영향': 377,\n",
              " '단': 378,\n",
              " '국제': 379,\n",
              " '계속': 380,\n",
              " 'a': 381,\n",
              " '동안': 382,\n",
              " '안전': 383,\n",
              " '목표': 384,\n",
              " '일부': 385,\n",
              " '더욱': 386,\n",
              " '온': 387,\n",
              " '역사': 388,\n",
              " '확보': 389,\n",
              " '년': 390,\n",
              " '7': 391,\n",
              " 'ces': 392,\n",
              " '자리': 393,\n",
              " '개인': 394,\n",
              " '또한': 395,\n",
              " '삶': 396,\n",
              " '연구': 397,\n",
              " '일이': 398,\n",
              " '지능': 399,\n",
              " '모델': 400,\n",
              " '스마트폰': 401,\n",
              " '인공': 402,\n",
              " '소득': 403,\n",
              " '물론': 404,\n",
              " '건설': 405,\n",
              " '그리고': 406,\n",
              " '데이터': 407,\n",
              " '가치': 408,\n",
              " '나라': 409,\n",
              " '선보이다': 410,\n",
              " '관심': 411,\n",
              " '기간': 412,\n",
              " '올리다': 413,\n",
              " '알려지다': 414,\n",
              " '업무': 415,\n",
              " '나타나다': 416,\n",
              " '8': 417,\n",
              " '여성': 418,\n",
              " '참석': 419,\n",
              " '해결': 420,\n",
              " '공간': 421,\n",
              " '양': 422,\n",
              " '도시': 423,\n",
              " '정': 424,\n",
              " '마음': 425,\n",
              " '만큼': 426,\n",
              " '면서': 427,\n",
              " '창': 428,\n",
              " '바': 429,\n",
              " '뜻': 430,\n",
              " '한편': 431,\n",
              " '만': 432,\n",
              " '보도': 433,\n",
              " '우려': 434,\n",
              " '역시': 435,\n",
              " '개월': 436,\n",
              " '더불다': 437,\n",
              " '지난달': 438,\n",
              " '환자': 439,\n",
              " '강화': 440,\n",
              " '자율': 441,\n",
              " '열다': 442,\n",
              " '쉬다': 443,\n",
              " '기능': 444,\n",
              " '떨어지다': 445,\n",
              " '도입': 446,\n",
              " '볼': 447,\n",
              " '조치': 448,\n",
              " '갖다': 449,\n",
              " '모르다': 450,\n",
              " '재': 451,\n",
              " '힘': 452,\n",
              " '11월': 453,\n",
              " '유지': 454,\n",
              " '여러': 455,\n",
              " '눈': 456,\n",
              " '알': 457,\n",
              " '선정': 458,\n",
              " '배': 459,\n",
              " '방문': 460,\n",
              " '구조': 461,\n",
              " '수도': 462,\n",
              " '박': 463,\n",
              " 'kt': 464,\n",
              " '상태': 465,\n",
              " '분': 466,\n",
              " '책': 467,\n",
              " '조성': 468,\n",
              " '이제': 469,\n",
              " '의지': 470,\n",
              " '경영': 471,\n",
              " '개혁': 472,\n",
              " '각': 473,\n",
              " '지적': 474,\n",
              " '북': 475,\n",
              " '영': 476,\n",
              " '이야기': 477,\n",
              " '경쟁': 478,\n",
              " '영상': 479,\n",
              " '상품': 480,\n",
              " '사고': 481,\n",
              " '20': 482,\n",
              " '경쟁력': 483,\n",
              " '대화': 484,\n",
              " '합의': 485,\n",
              " '신년': 486,\n",
              " '반': 487,\n",
              " '미세먼지': 488,\n",
              " '시설': 489,\n",
              " '한반도': 490,\n",
              " '가족': 491,\n",
              " '이미': 492,\n",
              " '인상': 493,\n",
              " '제시': 494,\n",
              " '새': 495,\n",
              " '작년': 496,\n",
              " '부분': 497,\n",
              " '전환': 498,\n",
              " '9': 499,\n",
              " '실제': 500,\n",
              " '오늘': 501,\n",
              " '시행': 502,\n",
              " '자료': 503,\n",
              " '주민': 504,\n",
              " '위원': 505,\n",
              " '가지다': 506,\n",
              " '체인': 507,\n",
              " '높이다': 508,\n",
              " '보내다': 509,\n",
              " '층': 510,\n",
              " '바라다': 511,\n",
              " '비다': 512,\n",
              " '만나다': 513,\n",
              " '해당': 514,\n",
              " '생활': 515,\n",
              " '강화하다': 516,\n",
              " '효과': 517,\n",
              " '북미': 518,\n",
              " '앞서': 519,\n",
              " '집중': 520,\n",
              " '전문가': 521,\n",
              " '통신': 522,\n",
              " '정상회담': 523,\n",
              " '해주다': 524,\n",
              " '바꾸다': 525,\n",
              " '경찰': 526,\n",
              " '석': 527,\n",
              " '뿐': 528,\n",
              " '경험': 529,\n",
              " '현실': 530,\n",
              " '글': 531,\n",
              " '향': 532,\n",
              " '전문': 533,\n",
              " '대응': 534,\n",
              " '최초': 535,\n",
              " '서': 536,\n",
              " '단계': 537,\n",
              " '창업': 538,\n",
              " '치료': 539,\n",
              " '로봇': 540,\n",
              " '애플': 541,\n",
              " '조직': 542,\n",
              " '자체': 543,\n",
              " '초': 544,\n",
              " '해오다': 545,\n",
              " '개최': 546,\n",
              " '우리나라': 547,\n",
              " '오': 548,\n",
              " '줄': 549,\n",
              " '대한민국': 550,\n",
              " '논의': 551,\n",
              " '무엇': 552,\n",
              " '살다': 553,\n",
              " '거': 554,\n",
              " '택시': 555,\n",
              " '스마트': 556,\n",
              " '은행': 557,\n",
              " '광주': 558,\n",
              " '상승': 559,\n",
              " '위기': 560,\n",
              " '기회': 561,\n",
              " '관광': 562,\n",
              " '4일': 563,\n",
              " '방안': 564,\n",
              " '피해': 565,\n",
              " '보호': 566,\n",
              " '다음': 567,\n",
              " '크게': 568,\n",
              " '알다': 569,\n",
              " '남북': 570,\n",
              " '부문': 571,\n",
              " '사이': 572,\n",
              " '물': 573,\n",
              " '집': 574,\n",
              " '제재': 575,\n",
              " '언급': 576,\n",
              " '중앙': 577,\n",
              " '블록': 578,\n",
              " '비판': 579,\n",
              " '구성': 580,\n",
              " '원내대표': 581,\n",
              " '담다': 582,\n",
              " '정권': 583,\n",
              " '매출': 584,\n",
              " '100': 585,\n",
              " '이뤄지다': 586,\n",
              " '액': 587,\n",
              " '인': 588,\n",
              " '혐의': 589,\n",
              " '부회장': 590,\n",
              " '건강': 591,\n",
              " '주행': 592,\n",
              " '의혹': 593,\n",
              " '돈': 594,\n",
              " '청년': 595,\n",
              " '디지털': 596,\n",
              " '언론': 597,\n",
              " '프로그램': 598,\n",
              " '본격': 599,\n",
              " '영업': 600,\n",
              " '인터넷': 601,\n",
              " '실적': 602,\n",
              " 'm': 603,\n",
              " '주의': 604,\n",
              " '선택': 605,\n",
              " '대책': 606,\n",
              " '활성화': 607,\n",
              " '공식': 608,\n",
              " '용': 609,\n",
              " '보유': 610,\n",
              " '영국': 611,\n",
              " '기해년': 612,\n",
              " '먼저': 613,\n",
              " '부': 614,\n",
              " '의료': 615,\n",
              " '검찰': 616,\n",
              " '의사': 617,\n",
              " '불': 618,\n",
              " '과거': 619,\n",
              " '결국': 620,\n",
              " '인하다': 621,\n",
              " '판단': 622,\n",
              " '이익': 623,\n",
              " '예': 624,\n",
              " '발언': 625,\n",
              " '연구원': 626,\n",
              " '갖추다': 627,\n",
              " '율': 628,\n",
              " '얘기': 629,\n",
              " '단체': 630,\n",
              " '기사': 631,\n",
              " 'ㆍ': 632,\n",
              " '먹다': 633,\n",
              " '방법': 634,\n",
              " '에너지': 635,\n",
              " '전쟁': 636,\n",
              " '안정': 637,\n",
              " 'd': 638,\n",
              " '남다': 639,\n",
              " '아직': 640,\n",
              " '소비자': 641,\n",
              " '살': 642,\n",
              " '우선': 643,\n",
              " '모바일': 644,\n",
              " '내리다': 645,\n",
              " '다만': 646,\n",
              " '1년': 647,\n",
              " '들이다': 648,\n",
              " '필요': 649,\n",
              " '발행': 650,\n",
              " '책임': 651,\n",
              " '중이': 652,\n",
              " '의견': 653,\n",
              " '신청': 654,\n",
              " '들어가다': 655,\n",
              " '장': 656,\n",
              " '대부분': 657,\n",
              " '얻다': 658,\n",
              " '그런데': 659,\n",
              " '작업': 660,\n",
              " '공동': 661,\n",
              " '국': 662,\n",
              " '화하다': 663,\n",
              " '빠르다': 664,\n",
              " '2016년': 665,\n",
              " '브랜드': 666,\n",
              " '주목': 667,\n",
              " '강하다': 668,\n",
              " '방향': 669,\n",
              " '매': 670,\n",
              " '부담': 671,\n",
              " '통합': 672,\n",
              " '채': 673,\n",
              " '명의': 674,\n",
              " '갈등': 675,\n",
              " '소통': 676,\n",
              " '별': 677,\n",
              " '이끌다': 678,\n",
              " '각각': 679,\n",
              " '어느': 680,\n",
              " '무역': 681,\n",
              " '학교': 682,\n",
              " '라스베이거스': 683,\n",
              " '최': 684,\n",
              " '이루다': 685,\n",
              " '공급': 686,\n",
              " '세대': 687,\n",
              " '논란': 688,\n",
              " '반도체': 689,\n",
              " '돼지': 690,\n",
              " '설치': 691,\n",
              " '비용': 692,\n",
              " '예산': 693,\n",
              " '평균': 694,\n",
              " '여기': 695,\n",
              " '2월': 696,\n",
              " '세상': 697,\n",
              " '이전': 698,\n",
              " '이름': 699,\n",
              " '기념': 700,\n",
              " '30': 701,\n",
              " '나다': 702,\n",
              " '현대': 703,\n",
              " '쓰다': 704,\n",
              " '이렇게': 705,\n",
              " '주년': 706,\n",
              " '제작': 707,\n",
              " '31일': 708,\n",
              " '감소': 709,\n",
              " '늘어나다': 710,\n",
              " '다르다': 711,\n",
              " '재판': 712,\n",
              " '3년': 713,\n",
              " '지키다': 714,\n",
              " '사랑': 715,\n",
              " '바로': 716,\n",
              " '맞추다': 717,\n",
              " '신재민': 718,\n",
              " '최저임금': 719,\n",
              " '실': 720,\n",
              " '보여주다': 721,\n",
              " '고용': 722,\n",
              " '매우': 723,\n",
              " '덧붙이다': 724,\n",
              " '역량': 725,\n",
              " '목소리': 726,\n",
              " '공연': 727,\n",
              " '위치': 728,\n",
              " '국무위원': 729,\n",
              " '신뢰': 730,\n",
              " '포인트': 731,\n",
              " '주택': 732,\n",
              " '신규': 733,\n",
              " '축제': 734,\n",
              " '장비': 735,\n",
              " '반대': 736,\n",
              " '텔레콤': 737,\n",
              " '공사': 738,\n",
              " '성공': 739,\n",
              " '거치다': 740,\n",
              " '시기': 741,\n",
              " '핵': 742,\n",
              " '체제': 743,\n",
              " '인식': 744,\n",
              " '열': 745,\n",
              " '여러분': 746,\n",
              " '대학': 747,\n",
              " '동시': 748,\n",
              " '증권': 749,\n",
              " '카카오': 750,\n",
              " '차례': 751,\n",
              " '로서': 752,\n",
              " '국채': 753,\n",
              " '유럽': 754,\n",
              " '능력': 755,\n",
              " '보수': 756,\n",
              " '함': 757,\n",
              " '적': 758,\n",
              " '민주': 759,\n",
              " '통한': 760,\n",
              " '희망': 761,\n",
              " '도전': 762,\n",
              " '느끼다': 763,\n",
              " '기대하다': 764,\n",
              " '1만': 765,\n",
              " '과제': 766,\n",
              " '맞이': 767,\n",
              " '소개': 768,\n",
              " '에는': 769,\n",
              " '사례': 770,\n",
              " '2년': 771,\n",
              " '처': 772,\n",
              " '커지다': 773,\n",
              " '나누다': 774,\n",
              " '놓다': 775,\n",
              " '기대': 776,\n",
              " '3월': 777,\n",
              " 'it': 778,\n",
              " '협의': 779,\n",
              " '제기': 780,\n",
              " '종합': 781,\n",
              " '대구': 782,\n",
              " '강': 783,\n",
              " '주가': 784,\n",
              " '정상': 785,\n",
              " '표현': 786,\n",
              " '조정': 787,\n",
              " '◇': 788,\n",
              " '작가': 789,\n",
              " '구매': 790,\n",
              " '특별': 791,\n",
              " '종목': 792,\n",
              " '거리': 793,\n",
              " '전시': 794,\n",
              " '모으다': 795,\n",
              " '호': 796,\n",
              " '시무': 797,\n",
              " '내놓다': 798,\n",
              " '당국': 799,\n",
              " '선거': 800,\n",
              " '달러': 801,\n",
              " '8일': 802,\n",
              " '잡다': 803,\n",
              " '작품': 804,\n",
              " '중소기업': 805,\n",
              " '순': 806,\n",
              " '누구': 807,\n",
              " '7일': 808,\n",
              " '감': 809,\n",
              " '존재': 810,\n",
              " '고려': 811,\n",
              " '기재부': 812,\n",
              " '온라인': 813,\n",
              " '기도': 814,\n",
              " '외': 815,\n",
              " '기온': 816,\n",
              " '도움': 817,\n",
              " '줄이다': 818,\n",
              " '맡다': 819,\n",
              " 's': 820,\n",
              " '체계': 821,\n",
              " '각종': 822,\n",
              " '반면': 823,\n",
              " '속도': 824,\n",
              " '이하': 825,\n",
              " '일반': 826,\n",
              " '수사': 827,\n",
              " '조선': 828,\n",
              " '유': 829,\n",
              " '방침': 830,\n",
              " '처리': 831,\n",
              " '요': 832,\n",
              " '겪다': 833,\n",
              " '아시아': 834,\n",
              " '그래서': 835,\n",
              " '듯': 836,\n",
              " '작다': 837,\n",
              " '중인': 838,\n",
              " '또는': 839,\n",
              " '주변': 840,\n",
              " '인간': 841,\n",
              " '위험': 842,\n",
              " '10월': 843,\n",
              " '스스로': 844,\n",
              " '울': 845,\n",
              " '키우다': 846,\n",
              " '검토': 847,\n",
              " '진료': 848,\n",
              " '도로': 849,\n",
              " '비교': 850,\n",
              " '공장': 851,\n",
              " '여전하다': 852,\n",
              " '지방': 853,\n",
              " '마지막': 854,\n",
              " '공공': 855,\n",
              " '제대로': 856,\n",
              " '걸리다': 857,\n",
              " '면': 858,\n",
              " '의하다': 859,\n",
              " '영화': 860,\n",
              " '차지': 861,\n",
              " '등장': 862,\n",
              " '답': 863,\n",
              " '말다': 864,\n",
              " '예술': 865,\n",
              " '해보다': 866,\n",
              " '서로': 867,\n",
              " '완전하다': 868,\n",
              " '반영': 869,\n",
              " '마을': 870,\n",
              " '대변인': 871,\n",
              " '자기': 872,\n",
              " '적다': 873,\n",
              " '설립': 874,\n",
              " '그것': 875,\n",
              " '이용자': 876,\n",
              " '미디어': 877,\n",
              " '폭': 878,\n",
              " '낮다': 879,\n",
              " '여부': 880,\n",
              " '걸': 881,\n",
              " '대형': 882,\n",
              " '장기': 883,\n",
              " '선언': 884,\n",
              " '완화': 885,\n",
              " '이해': 886,\n",
              " '모': 887,\n",
              " '인기': 888,\n",
              " '실시': 889,\n",
              " '바탕': 890,\n",
              " '이러하다': 891,\n",
              " '인정': 892,\n",
              " '위협': 893,\n",
              " '복지': 894,\n",
              " '자산': 895,\n",
              " '리': 896,\n",
              " '공유': 897,\n",
              " '몇': 898,\n",
              " '9월': 899,\n",
              " '호텔': 900,\n",
              " '늘리다': 901,\n",
              " '거나': 902,\n",
              " '네이버': 903,\n",
              " '미치다': 904,\n",
              " '원하다': 905,\n",
              " '프로젝트': 906,\n",
              " '부동산': 907,\n",
              " '즐기다': 908,\n",
              " '아침': 909,\n",
              " '대법원': 910,\n",
              " '학생': 911,\n",
              " '시각': 912,\n",
              " '대신': 913,\n",
              " '효율': 914,\n",
              " '발': 915,\n",
              " '시험': 916,\n",
              " 'apos': 917,\n",
              " '심사': 918,\n",
              " '향후': 919,\n",
              " '수석': 920,\n",
              " '시도': 921,\n",
              " '내부': 922,\n",
              " '∼': 923,\n",
              " '중단': 924,\n",
              " '교체': 925,\n",
              " '로부터': 926,\n",
              " '육성': 927,\n",
              " '18': 928,\n",
              " '남': 929,\n",
              " '비율': 930,\n",
              " '수요': 931,\n",
              " '이자': 932,\n",
              " '재정': 933,\n",
              " '지구': 934,\n",
              " '유튜브': 935,\n",
              " '그동안': 936,\n",
              " '의회': 937,\n",
              " '입': 938,\n",
              " '이사장': 939,\n",
              " '코리아': 940,\n",
              " '버리다': 941,\n",
              " '바람': 942,\n",
              " '구체': 943,\n",
              " '률': 944,\n",
              " '하루': 945,\n",
              " '의장': 946,\n",
              " '인터뷰': 947,\n",
              " '진': 948,\n",
              " '산업혁명': 949,\n",
              " '막다': 950,\n",
              " '고민': 951,\n",
              " '종': 952,\n",
              " '수익': 953,\n",
              " '기획': 954,\n",
              " '전달': 955,\n",
              " '수행': 956,\n",
              " '전기차': 957,\n",
              " '총리': 958,\n",
              " '갈다': 959,\n",
              " '군': 960,\n",
              " '너무': 961,\n",
              " '행동': 962,\n",
              " '생': 963,\n",
              " '차원': 964,\n",
              " '산': 965,\n",
              " '자금': 966,\n",
              " '진화': 967,\n",
              " '끝': 968,\n",
              " '세우다': 969,\n",
              " '질문': 970,\n",
              " '금': 971,\n",
              " '이벤트': 972,\n",
              " '확산': 973,\n",
              " '단지': 974,\n",
              " '형태': 975,\n",
              " '조건': 976,\n",
              " '과학기술': 977,\n",
              " '공격': 978,\n",
              " '치다': 979,\n",
              " '노조': 980,\n",
              " '앱': 981,\n",
              " '바뀌다': 982,\n",
              " '보장': 983,\n",
              " '부르다': 984,\n",
              " '측면': 985,\n",
              " '디자인': 986,\n",
              " '이미지': 987,\n",
              " '화재': 988,\n",
              " 'r': 989,\n",
              " '50': 990,\n",
              " '히': 991,\n",
              " '왜': 992,\n",
              " '원인': 993,\n",
              " '국정': 994,\n",
              " '앞두다': 995,\n",
              " '보이': 996,\n",
              " '홍': 997,\n",
              " '사업자': 998,\n",
              " '경북': 999,\n",
              " '체험': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsWEBY4Mf8hW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "3f3d70bb-f861-41df-e169-629c677c3bc7"
      },
      "source": [
        "#희귀단어 수 및 비율\n",
        "threshold = 3\n",
        "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합(vocabulary)의 크기 : 66345\n",
            "등장 빈도가 2번 이하인 희귀 단어의 수: 32741\n",
            "단어 집합에서 희귀 단어의 비율: 49.349611877308014\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 1.6324770190703548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmegePrDg2d3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 등장 횟수 2회 이하가 49%인데, 전체에서 보면 1.6%\n",
        "# 사실상 처리하는데 큰 영향 없을듯...? 배제시키자.\n",
        "# tokenizer가 부여한 인덱스가 숫자 커질수록 희소한 것임\n",
        "vocab_size = total_cnt - rare_cnt + 1 # 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거. 0번 패딩 토큰을 고려하여 +1\n",
        "\n",
        "tokenizer = Tokenizer(vocab_size) \n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn0weXcUht7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y_train과 y_test를 지정\n",
        "y_train = np.array(train_data['GT'])\n",
        "y_test = np.array(test_data['GT'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARZBPAyZ0vZA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bfe9bcee-46c1-4462-9392-a29e21472552"
      },
      "source": [
        "#y_train과 y_test도 str -> float 꼴로 바꿔줌\n",
        "dic_category = {'경제': 0, '생활문화': 1, 'IT과학': 2, '정치': 3, '사회': 4, '오피니언': 5, '세계':6}\n",
        "for i in range(len(y_train)):\n",
        "  y_train[i] = dic_category[y_train[i]]\n",
        "for i in range(len(y_test)):\n",
        "  y_test[i] = dic_category[y_test[i]]\n",
        "y_test[-10:]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 2, 4, 2, 3, 6, 5, 6, 3], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMCYTORribEg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "1d4e7c6a-9de0-4e0e-e0a4-556276087c23"
      },
      "source": [
        "# 희소 데이터로만 이루어져있던 데이터셋은 빈 리스트 형태로 있을테니 이것도 없애주자.\n",
        "# 단, 지금 데이터에서는 없어서 안해도 됨\n",
        "drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]\n",
        "drop_test = [index for index, sentence in enumerate(X_test) if len(sentence) < 1]\n",
        "print(len(drop_train), len(drop_test)) # 빈 데이터 셋 갯수 출력\n",
        "\n",
        "# 빈 데이터 셋([]) 제거 - 지금 데이터에선 제거 되는거 없음 ㅇㅇ\n",
        "X_train = np.delete(X_train, drop_train, axis=0)\n",
        "y_train = np.delete(y_train, drop_train, axis=0)\n",
        "print(len(X_train))\n",
        "print(len(y_train))\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0\n",
            "10000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnqv4PsCid7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "2233e855-6df3-4f67-b377-5abd711e06e6"
      },
      "source": [
        "# 전체 데이터 중 가장 긴 뉴스, 뉴스들 평균  길이로 어느정도 길이로 잘라낼지 확인\n",
        "print('뉴스 기사 최대 길이 :',max(len(l) for l in X_train))\n",
        "print('뉴스 기사 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
        "plt.hist([len(s) for s in X_train], bins=50)\n",
        "plt.xlabel('length of news')\n",
        "plt.ylabel('number of news')\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "뉴스 기사 최대 길이 : 4184\n",
            "뉴스 기사 평균 길이 : 250.6494\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5wRCfD_jq46",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f382f4f-8733-439b-8287-b98816ede1e8"
      },
      "source": [
        "#전체 데이터 중 특정 length 이하인 비율을 알려주는 함수\n",
        "def below_threshold_len(max_len, nested_list):\n",
        "  cnt = 0\n",
        "  for s in nested_list:\n",
        "    if(len(s) <= max_len):\n",
        "        cnt = cnt + 1\n",
        "  print('전체 데이터 중 길이가 %s 이하인 데이터의 비율: %s'%(max_len, (cnt / len(nested_list))*100))\n",
        "\n",
        "max_len = 800  # 위 그래프 보면서 임의로 값 넣어보면서 비율 확인\n",
        "below_threshold_len(max_len, X_train)\n",
        "\n",
        "# max len - 비율\n",
        "#   1000  - 98.83\n",
        "#    900  - 98.42\n",
        "#    800  - 97.82\n",
        "#    700  - 96.65\n",
        "#    600  - 94.36"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 데이터 중 길이가 800 이하인 데이터의 비율: 97.82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMclTErbkOGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모든 데이터의 길이를 앞서 설정한 max_len으로 맞춰줌\n",
        "X_train = pad_sequences(X_train, maxlen = max_len)\n",
        "X_test = pad_sequences(X_test, maxlen = max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8zXq_Fdl4Et",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################### \n",
        "############### 전처리 완료 ###################\n",
        "############################################### "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcIgsTpglt_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LSTM 구현 라이브러리 import\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDDbZTx6mQLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 제작 \n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 128)) # 임의로 output_dim 128으로 설정\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(7, activation = 'softmax')) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T0nEwhwzW8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validation_loss가 증가 -> overfitting의 징후이므로, 4회 이상 증가시 학습 조기 종료\n",
        "# ModelCheckpoint로 val_acc이 전보다 좋아질 경우에만 모델 저장\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmBpH5hkzyf8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "7acbc75e-effe-4084-cb30-018e1c166b82"
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/15\n",
            "7936/8000 [============================>.] - ETA: 2s - loss: 1.6148 - acc: 0.3637\n",
            "Epoch 00001: val_acc improved from -inf to 0.54150, saving model to best_model.h5\n",
            "8000/8000 [==============================] - 337s 42ms/sample - loss: 1.6128 - acc: 0.3651 - val_loss: 1.2756 - val_acc: 0.5415\n",
            "Epoch 2/15\n",
            "7936/8000 [============================>.] - ETA: 2s - loss: 0.8930 - acc: 0.6977\n",
            "Epoch 00002: val_acc improved from 0.54150 to 0.69050, saving model to best_model.h5\n",
            "8000/8000 [==============================] - 332s 42ms/sample - loss: 0.8918 - acc: 0.6982 - val_loss: 0.9293 - val_acc: 0.6905\n",
            "Epoch 3/15\n",
            "7936/8000 [============================>.] - ETA: 2s - loss: 0.4626 - acc: 0.8576\n",
            "Epoch 00003: val_acc did not improve from 0.69050\n",
            "8000/8000 [==============================] - 332s 41ms/sample - loss: 0.4626 - acc: 0.8576 - val_loss: 0.9827 - val_acc: 0.6855\n",
            "Epoch 4/15\n",
            "7936/8000 [============================>.] - ETA: 2s - loss: 0.2689 - acc: 0.9143\n",
            "Epoch 00004: val_acc did not improve from 0.69050\n",
            "8000/8000 [==============================] - 333s 42ms/sample - loss: 0.2702 - acc: 0.9140 - val_loss: 1.0627 - val_acc: 0.6785\n",
            "Epoch 5/15\n",
            "7936/8000 [============================>.] - ETA: 2s - loss: 0.1771 - acc: 0.9467\n",
            "Epoch 00005: val_acc did not improve from 0.69050\n",
            "8000/8000 [==============================] - 334s 42ms/sample - loss: 0.1778 - acc: 0.9464 - val_loss: 1.1922 - val_acc: 0.6825\n",
            "Epoch 6/15\n",
            "7936/8000 [============================>.] - ETA: 2s - loss: 0.1349 - acc: 0.9569\n",
            "Epoch 00006: val_acc did not improve from 0.69050\n",
            "8000/8000 [==============================] - 333s 42ms/sample - loss: 0.1347 - acc: 0.9570 - val_loss: 1.2599 - val_acc: 0.6745\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qao4S7Y6-fVx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "12b8862b-29e7-4dbe-9c74-fc81d676c6d0"
      },
      "source": [
        "loaded_model = load_model('best_model.h5')\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "1000/1000 [==============================] - 8s 8ms/sample - loss: 0.9535 - acc: 0.6690\n",
            "\n",
            " 테스트 정확도: 0.6690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA6lTjvU0GA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################################################\n",
        "################################################## MLP  \n",
        "#######  max_features -> vocab_size,  maxwords -> max_len\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import Flatten\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(vocab_size, 128, input_length=max_len))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(256, activation='relu'))\n",
        "model2.add(Dense(7, activation='softmax'))\n",
        "\n",
        "model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYZ6Ud1T_meQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "outputId": "b8ca8c38-7f5a-4d18-ef1f-b32ac2e25202"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# validation_loss가 증가 -> overfitting의 징후이므로, 4회 이상 증가시 학습 조기 종료\n",
        "# ModelCheckpoint로 val_acc이 전보다 좋아질 경우에만 모델 저장\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('best_model2.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "history = model2.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/15\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "8000/8000 [==============================] - 78s 10ms/step - loss: 1.6880 - acc: 0.4029 - val_loss: 1.0201 - val_acc: 0.6335\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.63350, saving model to best_model2.h5\n",
            "Epoch 2/15\n",
            "8000/8000 [==============================] - 74s 9ms/step - loss: 0.4954 - acc: 0.8505 - val_loss: 0.7439 - val_acc: 0.7465\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.63350 to 0.74650, saving model to best_model2.h5\n",
            "Epoch 3/15\n",
            "8000/8000 [==============================] - 73s 9ms/step - loss: 0.1306 - acc: 0.9654 - val_loss: 0.7446 - val_acc: 0.7640\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.74650 to 0.76400, saving model to best_model2.h5\n",
            "Epoch 4/15\n",
            "8000/8000 [==============================] - 73s 9ms/step - loss: 0.0745 - acc: 0.9789 - val_loss: 0.7894 - val_acc: 0.7570\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.76400\n",
            "Epoch 5/15\n",
            "8000/8000 [==============================] - 72s 9ms/step - loss: 0.0611 - acc: 0.9810 - val_loss: 0.8208 - val_acc: 0.7540\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.76400\n",
            "Epoch 6/15\n",
            "8000/8000 [==============================] - 72s 9ms/step - loss: 0.0559 - acc: 0.9826 - val_loss: 0.8381 - val_acc: 0.7535\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.76400\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE5bNZ3RGWi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0834a8ea-0881-4f52-ad14-0a0b17540929"
      },
      "source": [
        "loaded_model = load_model('best_model2.h5')\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.7400 - acc: 0.7660\n",
            "\n",
            " 테스트 정확도: 0.7660\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdFaqtFtEuL6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "5ee0380d-5cf5-4d70-cfad-58ebda258baa"
      },
      "source": [
        "##################################################\n",
        "################################################## CNN \n",
        "#######  max_features -> vocab_size,  max_words -> max_len\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Flatten, Dropout\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Embedding(vocab_size, 128, input_length=max_len))\n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(Conv1D(256,\n",
        "                 3,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model3.add(GlobalMaxPooling1D())\n",
        "model3.add(Dense(128, activation='relu'))\n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(Dense(7, activation='softmax'))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZud6wOUGpkl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "90f66ce3-3f87-4954-9718-8ad8bbec4b71"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# validation_loss가 증가 -> overfitting의 징후이므로, 4회 이상 증가시 학습 조기 종료\n",
        "# ModelCheckpoint로 val_acc이 전보다 좋아질 경우에만 모델 저장\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('best_model3.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "history = model3.fit(X_train, y_train, epochs=10, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/10\n",
            "8000/8000 [==============================] - 104s 13ms/step - loss: 1.6166 - acc: 0.4005 - val_loss: 1.0380 - val_acc: 0.6300\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.63000, saving model to best_model3.h5\n",
            "Epoch 2/10\n",
            "8000/8000 [==============================] - 103s 13ms/step - loss: 0.8267 - acc: 0.7114 - val_loss: 0.7104 - val_acc: 0.7455\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.63000 to 0.74550, saving model to best_model3.h5\n",
            "Epoch 3/10\n",
            "8000/8000 [==============================] - 103s 13ms/step - loss: 0.4806 - acc: 0.8435 - val_loss: 0.6453 - val_acc: 0.7685\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.74550 to 0.76850, saving model to best_model3.h5\n",
            "Epoch 4/10\n",
            "8000/8000 [==============================] - 103s 13ms/step - loss: 0.2641 - acc: 0.9191 - val_loss: 0.6310 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.76850 to 0.78050, saving model to best_model3.h5\n",
            "Epoch 5/10\n",
            "8000/8000 [==============================] - 103s 13ms/step - loss: 0.1521 - acc: 0.9569 - val_loss: 0.6750 - val_acc: 0.7860\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.78050 to 0.78600, saving model to best_model3.h5\n",
            "Epoch 6/10\n",
            "8000/8000 [==============================] - 103s 13ms/step - loss: 0.1012 - acc: 0.9720 - val_loss: 0.6940 - val_acc: 0.7910\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.78600 to 0.79100, saving model to best_model3.h5\n",
            "Epoch 7/10\n",
            "8000/8000 [==============================] - 103s 13ms/step - loss: 0.0776 - acc: 0.9788 - val_loss: 0.7491 - val_acc: 0.7840\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.79100\n",
            "Epoch 8/10\n",
            "8000/8000 [==============================] - 103s 13ms/step - loss: 0.0719 - acc: 0.9791 - val_loss: 0.7566 - val_acc: 0.7865\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.79100\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r33K-hnyG5sx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c087d648-1314-4b4f-8cea-bddb89c64aa7"
      },
      "source": [
        "loaded_model = load_model('best_model3.h5')\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 3s 3ms/sample - loss: 0.7298 - acc: 0.7840\n",
            "\n",
            " 테스트 정확도: 0.7840\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqF-_0GPKtCg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "c7ced017-faea-40d9-f889-da7142bbdc5c"
      },
      "source": [
        "##################################################\n",
        "################################################## RCNN\n",
        "#######  max_features -> vocab_size,  max_words -> max_len\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Flatten, Dropout\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "\n",
        "model4 = Sequential()\n",
        "model4.add(Embedding(vocab_size, 128, input_length=max_len))\n",
        "model4.add(Dropout(0.2))\n",
        "model4.add(Conv1D(256,\n",
        "                 3,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model4.add(MaxPooling1D(pool_size=4))\n",
        "model4.add(LSTM(128))\n",
        "model4.add(Dense(7, activation='softmax'))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwHYoX2UQV8P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "outputId": "72e34cdb-4ce2-48f0-a2f6-6f82fe800935"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# validation_loss가 증가 -> overfitting의 징후이므로, 4회 이상 증가시 학습 조기 종료\n",
        "# ModelCheckpoint로 val_acc이 전보다 좋아질 경우에만 모델 저장\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('best_model4.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "model4.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "history = model4.fit(X_train, y_train, epochs=10, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/10\n",
            "8000/8000 [==============================] - 174s 22ms/step - loss: 1.4874 - acc: 0.4275 - val_loss: 0.9996 - val_acc: 0.6475\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.64750, saving model to best_model3.h5\n",
            "Epoch 2/10\n",
            "8000/8000 [==============================] - 173s 22ms/step - loss: 0.6860 - acc: 0.7671 - val_loss: 0.9262 - val_acc: 0.7030\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.64750 to 0.70300, saving model to best_model3.h5\n",
            "Epoch 3/10\n",
            "8000/8000 [==============================] - 173s 22ms/step - loss: 0.3604 - acc: 0.8845 - val_loss: 0.8901 - val_acc: 0.7270\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.70300 to 0.72700, saving model to best_model3.h5\n",
            "Epoch 4/10\n",
            "8000/8000 [==============================] - 172s 22ms/step - loss: 0.2119 - acc: 0.9338 - val_loss: 1.0270 - val_acc: 0.7190\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.72700\n",
            "Epoch 5/10\n",
            "8000/8000 [==============================] - 172s 22ms/step - loss: 0.1412 - acc: 0.9555 - val_loss: 1.0745 - val_acc: 0.7100\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.72700\n",
            "Epoch 6/10\n",
            "8000/8000 [==============================] - 171s 21ms/step - loss: 0.1135 - acc: 0.9635 - val_loss: 1.1772 - val_acc: 0.7165\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.72700\n",
            "Epoch 7/10\n",
            "8000/8000 [==============================] - 171s 21ms/step - loss: 0.0997 - acc: 0.9670 - val_loss: 1.1810 - val_acc: 0.7115\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.72700\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSREVRXlQgj3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "12001fab-ce3b-43a0-f301-64f880f32842"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "loaded_model = load_model('best_model4.h5')\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 7s 7ms/sample - loss: 0.9434 - acc: 0.7260\n",
            "\n",
            " 테스트 정확도: 0.7260\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qkEU86PdOjC",
        "colab_type": "text"
      },
      "source": [
        "LSTM: 0.6690\n",
        "\n",
        "MLP: 0.7660\n",
        "\n",
        "CNN: 0.7840\n",
        "\n",
        "RCNN: 0.7260\n",
        "\n",
        "전처리부터 다시 해보자."
      ]
    }
  ]
}